{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/aitormorais/DIPC/blob/main/Cnn_but.ipynb",
      "authorship_tag": "ABX9TyM8zN8Vc6Q93+rSQ2fBk3AS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aitormorais/DIPC/blob/main/Cnn_but.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar librerias"
      ],
      "metadata": {
        "id": "gqXaJPEqujDC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DsEoyfnMueOV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from collections import Counter\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este cuaderno haremos uso de un [dataset](https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification)obtenido de kaggle"
      ],
      "metadata": {
        "id": "Y3zT2Xxov4sC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo tengo almacenado en drive, por lo que tendremos que montar el drive"
      ],
      "metadata": {
        "id": "Xp20QNZBwUAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 1: Importar la biblioteca de drive"
      ],
      "metadata": {
        "id": "8_pUFHvgwg0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "2QMq6aftv4ZK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 2: Montar la carpeta"
      ],
      "metadata": {
        "id": "JxkjBuc-wlfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXCAX8BtwpVh",
        "outputId": "2b1cc4dd-5afa-4dfd-c06d-d3e7d9aa79d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 3: Cargar datos de entrenamiento"
      ],
      "metadata": {
        "id": "KozCviQUI_Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Cnn_data/Training_set.csv')"
      ],
      "metadata": {
        "id": "SjigVUOkw54C",
        "outputId": "c678a4d8-5be7-4069-8b1b-2d5000dceb13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-422f3de6b905>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Cnn_data/Training_set.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Cnn_data/Training_set.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/Cnn_data/Testing_set.csv')"
      ],
      "metadata": {
        "id": "nzf12cudQODt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nombres = sorted(train['label'].unique())"
      ],
      "metadata": {
        "id": "TsFSjgNYzL3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 5: Contamos por cada clase cuantas imagenes tenemos"
      ],
      "metadata": {
        "id": "qQOXJMfVJPfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter(train['label'])"
      ],
      "metadata": {
        "id": "V7GFQW9dLxYx",
        "outputId": "8512b3f1-adca-4931-f4a5-798cd558b8e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-836a4c3df4b5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Esta la suma bien hecha?"
      ],
      "metadata": {
        "id": "EO5LGqSDJ1b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert sum(counter.values()) == len(train['label']), \"La suma no está bien hecha.\""
      ],
      "metadata": {
        "id": "QvvciMlDLz0Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficamos el dataset"
      ],
      "metadata": {
        "id": "UUuCCruzJ6Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "plt.bar(diccionario.keys(), diccionario.values())\n",
        "plt.title('Distribución de clases en el conjunto de datos')\n",
        "plt.xlabel('Clases')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.xticks(rotation=90) # Esto rota los nombres de las clases en el eje x para mejorar la visibilidad\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "SObdLLOW1Wgz",
        "outputId": "fa290bcb-9677-4f39-bda5-c19b35e8fce7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3ec30de33609>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiccionario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiccionario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Distribución de clases en el conjunto de datos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Clases'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cantidad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'diccionario' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_porcentajes(counter):\n",
        "    \"\"\"Calcula el porcentaje de cada clase en el diccionario proporcionado.\"\"\"\n",
        "    total = sum(counter.values())\n",
        "    return {nombre: (valor / total) * 100 for nombre, valor in counter.items()}"
      ],
      "metadata": {
        "id": "OVh73RuvIQ53"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imprimir_porcentajes(porcentajes):\n",
        "    \"\"\"Imprime los porcentajes en un formato legible.\"\"\"\n",
        "    # Imprimir los porcentajes\n",
        "    for nombre, valor in porcentajes.items():\n",
        "        print(f'{nombre}: {valor:.2f}%')"
      ],
      "metadata": {
        "id": "U4YB0tB9IT6r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimos el porcentaje, es decir que porcentaje representa cada clase del dataset"
      ],
      "metadata": {
        "id": "h2fQcguSJ94k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular los porcentajes\n",
        "porcentajes = calcular_porcentajes(counter)"
      ],
      "metadata": {
        "id": "EBMZjdcJMSq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Imprimir los porcentajes\n",
        "imprimir_porcentajes(porcentajes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdLUHrI7INF6",
        "outputId": "18d6a234-ac02-4942-e74b-0640bf68474c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SOUTHERN DOGFACE: 1.34%\n",
            "ADONIS: 1.35%\n",
            "BROWN SIPROETA: 1.52%\n",
            "MONARCH: 1.38%\n",
            "GREEN CELLED CATTLEHEART: 1.35%\n",
            "CAIRNS BIRDWING: 1.28%\n",
            "EASTERN DAPPLE WHITE: 1.42%\n",
            "RED POSTMAN: 1.37%\n",
            "MANGROVE SKIPPER: 1.34%\n",
            "BLACK HAIRSTREAK: 1.31%\n",
            "CABBAGE WHITE: 1.38%\n",
            "RED ADMIRAL: 1.26%\n",
            "PAINTED LADY: 1.20%\n",
            "PAPER KITE: 1.38%\n",
            "SOOTYWING: 1.38%\n",
            "PINE WHITE: 1.32%\n",
            "PEACOCK: 1.29%\n",
            "CHECQUERED SKIPPER: 1.46%\n",
            "JULIA: 1.25%\n",
            "COMMON WOOD-NYMPH: 1.38%\n",
            "BLUE MORPHO: 1.15%\n",
            "CLOUDED SULPHUR: 1.42%\n",
            "STRAITED QUEEN: 1.34%\n",
            "ORANGE OAKLEAF: 1.34%\n",
            "PURPLISH COPPER: 1.42%\n",
            "ATALA: 1.54%\n",
            "IPHICLUS SISTER: 1.46%\n",
            "DANAID EGGFLY: 1.45%\n",
            "LARGE MARBLE: 1.25%\n",
            "PIPEVINE SWALLOW: 1.29%\n",
            "BLUE SPOTTED CROW: 1.32%\n",
            "RED CRACKER: 1.48%\n",
            "QUESTION MARK: 1.18%\n",
            "CRIMSON PATCH: 1.11%\n",
            "BANDED PEACOCK: 1.28%\n",
            "SCARCE SWALLOW: 1.49%\n",
            "COPPER TAIL: 1.45%\n",
            "GREAT JAY: 1.45%\n",
            "INDRA SWALLOW: 1.25%\n",
            "VICEROY: 1.25%\n",
            "MALACHITE: 1.12%\n",
            "APPOLLO: 1.38%\n",
            "TWO BARRED FLASHER: 1.17%\n",
            "MOURNING CLOAK: 2.02%\n",
            "TROPICAL LEAFWING: 1.28%\n",
            "POPINJAY: 1.31%\n",
            "ORANGE TIP: 1.48%\n",
            "GOLD BANDED: 1.12%\n",
            "BECKERS WHITE: 1.25%\n",
            "RED SPOTTED PURPLE: 1.32%\n",
            "MILBERTS TORTOISESHELL: 1.48%\n",
            "SILVER SPOT SKIPPER: 1.28%\n",
            "AMERICAN SNOOT: 1.14%\n",
            "AN 88: 1.31%\n",
            "ULYSES: 1.29%\n",
            "COMMON BANDED AWL: 1.34%\n",
            "CRECENT: 1.49%\n",
            "METALMARK: 1.17%\n",
            "SLEEPY ORANGE: 1.65%\n",
            "PURPLE HAIRSTREAK: 1.22%\n",
            "ELBOWED PIERROT: 1.26%\n",
            "GREAT EGGFLY: 1.20%\n",
            "ORCHARD SWALLOW: 1.17%\n",
            "ZEBRA LONG WING: 1.17%\n",
            "WOOD SATYR: 1.09%\n",
            "MESTRA: 1.32%\n",
            "EASTERN PINE ELFIN: 1.46%\n",
            "EASTERN COMA: 1.43%\n",
            "YELLOW SWALLOW TAIL: 1.15%\n",
            "CLEOPATRA: 1.43%\n",
            "GREY HAIRSTREAK: 1.32%\n",
            "BANDED ORANGE HELICONIAN: 1.49%\n",
            "AFRICAN GIANT SWALLOWTAIL: 1.15%\n",
            "CHESTNUT: 1.31%\n",
            "CLODIUS PARNASSIAN: 1.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empezamos con la CNN"
      ],
      "metadata": {
        "id": "2pjM1vguKJFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def img_prepoces(ruta, tupla):\n",
        "    \"\"\"\n",
        "    Función para leer, convertir y redimensionar una imagen utilizando OpenCV.\n",
        "\n",
        "    Parámetros:\n",
        "    - ruta (str): Una cadena que representa la ruta del archivo de imagen a procesar.\n",
        "    - tupla (tuple): Un tuple que contiene dos elementos que representan la altura y el ancho (respectivamente) a los que se debe redimensionar la imagen.\n",
        "\n",
        "    Devoluciones:\n",
        "    - ndarray: Una matriz Numpy que representa la imagen procesada y normalizada.\n",
        "\n",
        "    Esta función realiza los siguientes pasos:\n",
        "    1. Lee la imagen de la ruta especificada usando `cv2.imread()`.\n",
        "    2. Convierte la imagen de BGR a RGB usando `cv2.cvtColor()`.\n",
        "    3. Redimensiona la imagen al tamaño especificado por la tupla usando `cv2.resize()`.\n",
        "    4. Normaliza la imagen dividiéndola por 255. Esto se hace para cambiar los valores de los píxeles de la imagen de 0-255 a 0-1, un rango más adecuado para el entrenamiento de modelos de red neuronal.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(ruta)\n",
        "    if img is None:\n",
        "        print(f\"Couldn't read the image at {ruta}.\")\n",
        "        return None\n",
        "    return cv2.resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), (tupla[0], tupla[1])) / 255"
      ],
      "metadata": {
        "id": "gAn5zjXUKLWJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construir_modelo_fc(forma_entrada, func_acti, num_capas, filtro_inicial, n_clases, n_neuronas_fc):\n",
        "    \"\"\"\n",
        "    Función para construir una red neuronal convolucional (CNN) con Keras.\n",
        "\n",
        "    Parámetros:\n",
        "    - forma_entrada (tuple): Un tuple que define la forma de los datos de entrada (altura, ancho, canales).\n",
        "    - func_acti (str): Una cadena que define la función de activación a utilizar en las capas convolucionales y densas. Ejemplos: 'relu', 'sigmoid', 'tanh'.\n",
        "    - num_capas (int): Un entero que define el número de capas convolucionales a añadir a la red.\n",
        "    - filtro_inicial (int): Un entero que define el número de filtros en la primera capa convolucional. Las capas convolucionales subsiguientes duplicarán el número de filtros.\n",
        "    - n_clases (int): Un entero que define el número de clases objetivo para la clasificación.\n",
        "    - n_neuronas_fc (int): Un entero que define el número de neuronas en la capa totalmente conectada (capa densa).\n",
        "\n",
        "    Devoluciones:\n",
        "    - model (keras.Model): El modelo de la red neuronal convolucional.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filtro_inicial, (3, 3), activation=func_acti, input_shape=forma_entrada))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    for i in range(1, num_capas):\n",
        "        model.add(Conv2D(filtro_inicial*(2**i), (3, 3), activation=func_acti))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "    #Añadir capas densas\n",
        "    model.add(Flatten())#importante esta capa ya que convierte 2d a 1d para capas densas\n",
        "    model.add(Dense(n_neuronas_fc, activation=func_acti))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(n_clases, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "wsZbPfT5K5fg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convertir_labels_one_hot(ytrain, yval):\n",
        "    \"\"\"\n",
        "    Esta función convierte las etiquetas categóricas de texto a formato one-hot.\n",
        "\n",
        "    Argumentos:\n",
        "        ytrain: Serie de pandas o array de NumPy que contiene las etiquetas de las muestras de entrenamiento.\n",
        "        yval: Serie de pandas o array de NumPy que contiene las etiquetas de las muestras de validación.\n",
        "\n",
        "    Retorna:\n",
        "        Dos arrays de NumPy que representan las etiquetas de las muestras de entrenamiento y validación,\n",
        "        respectivamente, en formato one-hot.\n",
        "    \"\"\"\n",
        "\n",
        "    # Crear el codificador\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    # Ajustar el codificador a las etiquetas de entrenamiento y transformar las etiquetas a números enteros\n",
        "    y_train_int = le.fit_transform(ytrain)\n",
        "\n",
        "    # Utilizar el codificador ajustado para transformar las etiquetas de validación a números enteros\n",
        "    y_val_int = le.transform(yval)\n",
        "\n",
        "    # Convertir los números enteros a formato one-hot y devolverlos\n",
        "    return to_categorical(y_train_int), to_categorical(y_val_int)"
      ],
      "metadata": {
        "id": "AeNF48QmK9kx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dimensiones(ruta):\n",
        "    \"\"\"\n",
        "    Función para obtener las dimensiones de una imagen utilizando OpenCV.\n",
        "\n",
        "    Parámetros:\n",
        "    - ruta (str): Una cadena que representa la ruta del archivo de imagen a procesar.\n",
        "\n",
        "    Devoluciones:\n",
        "    - tuple: Un tuple que contiene las dimensiones de la imagen. El formato de la tupla devuelta es (altura, ancho, canales), donde 'canales' generalmente es 3 para imágenes en color (RGB).\n",
        "\n",
        "    Esta función realiza los siguientes pasos:\n",
        "    1. Lee la imagen de la ruta especificada usando `cv2.imread()`.\n",
        "    2. Convierte la imagen de BGR a RGB usando `cv2.cvtColor()`.\n",
        "    3. Devuelve la forma de la matriz de la imagen usando el atributo `.shape` de numpy, que representa las dimensiones de la imagen.\n",
        "    \"\"\"\n",
        "    return cv2.cvtColor(cv2.imread(ruta), cv2.COLOR_BGR2RGB).shape\n"
      ],
      "metadata": {
        "id": "Fm_AxZkOMc53"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensiones('/content/drive/MyDrive/Cnn_data/train/Image_1.jpg')[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA1_8Vd_MuiJ",
        "outputId": "ed8af5ac-5d09-4b14-8e90-eb6692a185f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CARGAR A LOCAL"
      ],
      "metadata": {
        "id": "58nl103aMvOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n"
      ],
      "metadata": {
        "id": "DWkuXepoWrCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "wYOdZKeAZqp-",
        "outputId": "ef240749-c95f-4d0a-8d15-246a2120717c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "archive.zip  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Reemplaza 'nombre_archivo.zip' con el nombre de tu archivo zip\n",
        "with zipfile.ZipFile('archive.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/cnn_but/')\n"
      ],
      "metadata": {
        "id": "SpjyDWSzXhI5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/"
      ],
      "metadata": {
        "id": "cR-lyUh0QzSn",
        "outputId": "1e1f972f-9295-49cc-a83c-c129a573ab8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MyDrive/"
      ],
      "metadata": {
        "id": "ru38zD1ERzB3",
        "outputId": "8425b1a8-0702-4d49-f2f5-1976c8429a52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "G3s820V6R3AH",
        "outputId": "1d1d1b19-1f0c-4545-bc4d-a1c720f75105",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "archive.zip  \u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "v5S9y5H2SBx0",
        "outputId": "44b8ed45-cdb4-43cf-c65e-ff42ed5e2c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://drive.google.com/file/d/15lHL8pdmkbi9HeWD4b7ZrnESRBOCSpzg/view?usp=drive_link"
      ],
      "metadata": {
        "id": "6eTkxRdaSwsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "DgwZUBi3Qs-3",
        "outputId": "5d04c7e0-284c-4792-9ec1-fcb0accccfda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/cnn_but\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-Dividir el dataset en train y validation"
      ],
      "metadata": {
        "id": "ImZsqJHfL64N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/cnn_but/Training_set.csv')"
      ],
      "metadata": {
        "id": "VNac9VNbVJxv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crear el array donde guardaremos las imagenes en forma de matrix\n",
        "train_img = []"
      ],
      "metadata": {
        "id": "vCx1eqZQMAR9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-Convertir las imagenes a una matrix"
      ],
      "metadata": {
        "id": "A6xPXnkkMLjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://drive.google.com/file/d/10_Kqvd5Eg9Ej8N46TIm6JFb1T70RZnuM/view?usp=drive_link"
      ],
      "metadata": {
        "id": "yqUIbF_oZD17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://drive.google.com/file/d/10_Kqvd5Eg9Ej8N46TIm6JFb1T70RZnuM/view?usp=sharing"
      ],
      "metadata": {
        "id": "KLtIthggZiKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name in tqdm(train['filename']):\n",
        "    nombre = \"/content/drive/MyDrive/cnn_but/train/\"+name\n",
        "    train_img.append(img_prepoces(nombre,dimensiones(nombre)[:2]))"
      ],
      "metadata": {
        "id": "jOzzTDM3dRg0",
        "outputId": "0d65d8f4-7816-4506-bb90-d53f9305846c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6499/6499 [00:41<00:00, 154.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-Guardar las etiquetas"
      ],
      "metadata": {
        "id": "6pXrbiL8OLHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = train['label']"
      ],
      "metadata": {
        "id": "yQVthacEOO-A"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-Dividir los datos"
      ],
      "metadata": {
        "id": "u9ZonU8SOTwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_img, X_val_img, y_train_names, y_val_names = train_test_split(train_img, names, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "49wAva8SOXSJ",
        "outputId": "86538813-0773-4813-8164-45845846c5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-67af64acd1af>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resize:\n",
        " se espera que las imagenes de entrada esten en un array 4d, con forma (numero de imagenes,altura,ancho,canales)"
      ],
      "metadata": {
        "id": "OwQeqH59OfH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_img = np.array(X_train_img).reshape(-1, 224, 224, 3)\n",
        "X_val_img = np.array(X_val_img).reshape(-1, 224, 224, 3)"
      ],
      "metadata": {
        "id": "TgAhgIXcOs5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos los parametros para hacer uso del data augmentation"
      ],
      "metadata": {
        "id": "EXOLMuzrPxNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un generador de datos de imagen con aumentación\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=30,  # Rotar aleatoriamente las imágenes\n",
        "        zoom_range = 0.1, # Zoom aleatoriamente las imágenes dentro del rango\n",
        "        width_shift_range=0.1,  # Desplazar aleatoriamente las imágenes horizontalmente\n",
        "        height_shift_range=0.1,  # Desplazar aleatoriamente las imágenes verticalmente\n",
        "        horizontal_flip=True,  # Invertir aleatoriamente las imágenes horizontalmente\n",
        "        vertical_flip=False)  # No invertir las imágenes verticalmente"
      ],
      "metadata": {
        "id": "_Sdf7Y4lP2VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajustamos el generador de datos a los datos de entrenamiento"
      ],
      "metadata": {
        "id": "EFMw1ZPrQCnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen.fit(X_train_img)"
      ],
      "metadata": {
        "id": "l5TlJ0EMQIRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos las etiquetas a formato one-hot"
      ],
      "metadata": {
        "id": "Muy5Isw-QxLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_names,y_val_names = convertir_labels_one_hot(y_train_names, y_val_names)"
      ],
      "metadata": {
        "id": "yObtDe7sQ2s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks"
      ],
      "metadata": {
        "id": "bee8XU3JRBQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint(\"mejor.h5\", save_best_only=True),  # Guarda el mejor modelo como 'mejor_modelo.h5'\n",
        "    EarlyStopping(patience=10, restore_best_weights=True),  # Detén el entrenamiento si el modelo deja de mejorar\n",
        "    ReduceLROnPlateau(patience=5)  # Reduce la tasa de aprendizaje si el modelo deja de mejorar\n",
        "]\n"
      ],
      "metadata": {
        "id": "Y9I4jf4pRDOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el modelo"
      ],
      "metadata": {
        "id": "wbfVbQAMQ4__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = construir_modelo_fc((224,224,3),'relu',4,16,75,512)"
      ],
      "metadata": {
        "id": "YPEw61AvQ87X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilamos el modelo"
      ],
      "metadata": {
        "id": "dr7cGnuVRIeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy','precision'])\n"
      ],
      "metadata": {
        "id": "R180eiJHY61G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tAQVTrsyRLb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos el modelo"
      ],
      "metadata": {
        "id": "c0n4sf-2ROh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = modelo.fit(datagen.flow(X_train_img, y_train_names, batch_size=32),\n",
        "                    validation_data=(X_val_img, y_val_names),\n",
        "                    steps_per_epoch=len(X_train_img) // 32,\n",
        "                    epochs=100)"
      ],
      "metadata": {
        "id": "wyIrhx0fRQHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.save('mejor_modelo.keras')"
      ],
      "metadata": {
        "id": "qR_P-0GFZdS2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}