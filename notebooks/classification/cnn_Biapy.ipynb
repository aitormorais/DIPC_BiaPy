{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://drive.google.com/file/d/1GBsn30dCC_XjGwtFLyMMhnAwTLFzW3vV/view?usp=sharing"
      ],
      "metadata": {
        "id": "lHhP1oeroQoV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlmfjb8CnNH0",
        "outputId": "e80bd78a-e42d-4153-98fa-fc0a6d37d32d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped under /content/data\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to download an example dataset\n",
        "\n",
        "import os\n",
        "\n",
        "os.chdir('/content/')\n",
        "!curl -L -s -o archive.zip 'https://drive.google.com/uc?id=1GBsn30dCC_XjGwtFLyMMhnAwTLFzW3vV&confirm=t'\n",
        "\n",
        "!unzip -q archive.zip\n",
        "!rm archive.zip\n",
        "\n",
        "print('Dataset downloaded and unzipped under /content/data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Play to install BiaPy and its dependences\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.io import imread\n",
        "from skimage.exposure import match_histograms\n",
        "\n",
        "# Clone the repo\n",
        "os.chdir('/content/')\n",
        "if not os.path.exists('BiaPy'):\n",
        "    !git clone --depth 1 https://github.com/danifranco/BiaPy.git\n",
        "    !pip install --upgrade --no-cache-dir gdown &> /dev/null\n",
        "    sys.path.insert(0, 'BiaPy')\n",
        "    os.chdir('/content/BiaPy')\n",
        "\n",
        "    # Install dependencies\n",
        "    !pip install git+https://github.com/aleju/imgaug.git &> /dev/null\n",
        "    !pip install numpy_indexed yacs fill_voids edt &> /dev/null\n",
        "else:\n",
        "    print( 'Using existing installed version of BiaPy' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzXhuVDZqF71",
        "outputId": "c9bda6e1-a514-4143-df3c-1fd8a7467548"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BiaPy'...\n",
            "remote: Enumerating objects: 157, done.\u001b[K\n",
            "remote: Counting objects: 100% (157/157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 157 (delta 43), reused 85 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (157/157), 26.38 MiB | 17.49 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #####Path to train images\n",
        "train_data_path = '/content/data/train' #@param {type:\"string\"}\n",
        "#@markdown #####Path to validation images (necessary only if you do not want to extract validation from train, i.e. when **validation_from_train** variable below is **False**)\n",
        "#val_data_path = '/content/data/validation' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test images\n",
        "test_data_path = '/content/data/test' #@param {type:\"string\"}\n",
        "#@markdown #####Path to store the resulting images (it'll be created if not existing):\n",
        "output_path = '/content/output' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "SnL0-ongDVOI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Name of the model:\n",
        "model_name = \"my_2d_classification_but\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Data management:\n",
        "validation_from_train = True #@param {type:\"boolean\"}\n",
        "percentage_validation =  20 #@param {type:\"number\"}\n",
        "test_ground_truth = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Basic training parameters:\n",
        "number_of_classes = 11#@param {type:\"number\"}\n",
        "number_of_epochs =  2#@param {type:\"number\"}\n",
        "patience =  6#@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Advanced training parameters:\n",
        "\n",
        "model_architecture = \"simple_cnn\" #@param [\"EfficientNetB0\", \"simple_cnn\",\"ViT\"]\n",
        "\n",
        "batch_size =  12#@param {type:\"number\"}\n",
        "patch_size = 224 #@param {type:\"number\"}\n",
        "\n",
        "input_channels = 3 #@param {type:\"number\"}\n",
        "\n",
        "optimizer = \"ADAMW\" #@param [\"ADAM\", \"SGD\",\"ADAMW\"]\n",
        "initial_learning_rate = 0.001 #@param {type:\"number\"}"
      ],
      "metadata": {
        "id": "3JgnTxsqrDyE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Play to download the YAML configuration file and update it to train the model\n",
        "import errno\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# remove previous configuration file if it exists with the same name\n",
        "if os.path.exists( yaml_file ):\n",
        "    os.remove( yaml_file )\n",
        "\n",
        "# Download template file\n",
        "import shutil\n",
        "shutil.copy(\"/content/BiaPy/templates/classification/classification_2d.yaml\", yaml_file)\n",
        "\n",
        "# Check folders before modifying the .yaml file\n",
        "if not os.path.exists(train_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_data_path)\n",
        "ids = sorted(next(os.walk(train_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(train_data_path))\n",
        "\n",
        "\"\"\"if not os.path.exists(val_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), val_data_path)\n",
        "ids = sorted(next(os.walk(val_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(val_data_path))\"\"\"\n",
        "\n",
        "if not os.path.exists(test_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_data_path)\n",
        "ids = sorted(next(os.walk(test_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(test_data_path))\n",
        "\n",
        "\n",
        "# open template configuration file\n",
        "import yaml\n",
        "with open( yaml_file, 'r') as stream:\n",
        "    try:\n",
        "        biapy_config = yaml.safe_load(stream)\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)\n",
        "\n",
        "# update paths to data\n",
        "#DATA.NORMALIZATION.TYPE\n",
        "\n",
        "\n",
        "biapy_config['DATA']['TRAIN']['PATH'] = train_data_path\n",
        "biapy_config['DATA']['VAL']['PATH'] = val_data_path\n",
        "biapy_config['DATA']['TEST']['PATH'] = test_data_path\n",
        "biapy_config['DATA']['TEST']['LOAD_GT'] = test_ground_truth\n",
        "\n",
        "# update data patch size\n",
        "biapy_config['DATA']['PATCH_SIZE'] = '('+str(patch_size)+', '+ str(patch_size)+', ' + str(input_channels)+')'\n",
        "# adjust test padding accordingly\n",
        "padding = patch_size // 8\n",
        "biapy_config['DATA']['TEST']['PADDING'] = '('+str(padding)+', '+ str(padding)+')'\n",
        "\n",
        "# update training parameters\n",
        "biapy_config['DATA']['VAL']['FROM_TRAIN'] = validation_from_train\n",
        "biapy_config['DATA']['VAL']['SPLIT_TRAIN'] = percentage_validation/100.0\n",
        "biapy_config['TRAIN']['EPOCHS'] = number_of_epochs\n",
        "biapy_config['TRAIN']['PATIENCE'] = patience\n",
        "biapy_config['TRAIN']['BATCH_SIZE'] = batch_size\n",
        "biapy_config['TRAIN']['OPTIMIZER'] = optimizer\n",
        "biapy_config['TRAIN']['LR'] = initial_learning_rate\n",
        "\n",
        "# Transcribe model architecture\n",
        "# Available models: \"simple_cnn\", \"EfficientNetB0\"\n",
        "architecture = \"simple_cnn\"\n",
        "if model_architecture == \"simple_cnn\":\n",
        "    architecture = 'simple_cnn'\n",
        "if model_architecture == \"ViT\":\n",
        "    architecture = 'ViT'\n",
        "    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n",
        "    biapy_config['MODEL']['VIT_HIDDEN_SIZE'] = 768\n",
        "    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 12\n",
        "    biapy_config['MODEL']['VIT_NUM_HEADS'] = 12\n",
        "    biapy_config['MODEL']['VIT_MLP_DIMS'] = 3072\n",
        "else:\n",
        "    architecture = 'EfficientNetB0'\n",
        "biapy_config['MODEL']['N_CLASSES'] = number_of_classes\n",
        "biapy_config['MODEL']['ARCHITECTURE'] = architecture\n",
        "biapy_config['MODEL']['SPATIAL_DROPOUT'] =  True\n",
        "\n",
        "# save file\n",
        "with open( yaml_file, 'w') as outfile:\n",
        "    yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Training configuration finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "YhPkP9eBETVA",
        "outputId": "932babba-83d3-46c2-ff32-951dc2601d79"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-04d773fc5650>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No folders found in dir {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \"\"\"if not os.path.exists(val_data_path):\n",
            "\u001b[0;31mValueError\u001b[0m: No folders found in dir /content/data/train"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Play to train the model\n",
        "\n",
        "import os\n",
        "import errno\n",
        "\n",
        "# Run the code\n",
        "os.chdir('/content/BiaPy')\n",
        "!python -u main.py --config '/content/'{job_name}'.yaml' --result_dir {output_path} --name {job_name} --run_id 1 --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vDe7ZltiIuj",
        "outputId": "2916a37a-2d8b-4cac-fe6f-f6b42d49f529"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date: 2023-07-21 12:59:37\n",
            "Arguments: Namespace(config='/content/my_2d_classification_but.yaml', result_dir='/content/output', name='my_2d_classification_but', run_id=1, gpu='0')\n",
            "Job: my_2d_classification_but_1\n",
            "Python       : 3.10.6 (main, May 29 2023, 11:10:38) [GCC 11.3.0]\n",
            "Keras        : 2.12.0\n",
            "Tensorflow   : 2.12.0\n",
            "Num GPUs Available:  0\n",
            "Configuration details:\n",
            "AUGMENTOR:\n",
            "  AFFINE_MODE: constant\n",
            "  AUG_NUM_SAMPLES: 10\n",
            "  AUG_SAMPLES: True\n",
            "  BRIGHTNESS: False\n",
            "  BRIGHTNESS_EM: False\n",
            "  BRIGHTNESS_EM_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_EM_MODE: 3D\n",
            "  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_MODE: 3D\n",
            "  CBLUR_DOWN_RANGE: (2, 8)\n",
            "  CBLUR_INSIDE: True\n",
            "  CBLUR_SIZE: (0.2, 0.4)\n",
            "  CHANNEL_SHUFFLE: False\n",
            "  CMIX_SIZE: (0.2, 0.4)\n",
            "  CNOISE_NB_ITERATIONS: (1, 3)\n",
            "  CNOISE_SCALE: (0.05, 0.1)\n",
            "  CNOISE_SIZE: (0.2, 0.4)\n",
            "  CONTRAST: False\n",
            "  CONTRAST_EM: False\n",
            "  CONTRAST_EM_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_EM_MODE: 3D\n",
            "  CONTRAST_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_MODE: 3D\n",
            "  COUT_APPLY_TO_MASK: False\n",
            "  COUT_CVAL: 0.0\n",
            "  COUT_NB_ITERATIONS: (1, 3)\n",
            "  COUT_SIZE: (0.05, 0.3)\n",
            "  CUTBLUR: False\n",
            "  CUTMIX: False\n",
            "  CUTNOISE: False\n",
            "  CUTOUT: False\n",
            "  DA_PROB: 0.5\n",
            "  DRAW_GRID: True\n",
            "  DROPOUT: False\n",
            "  DROP_RANGE: (0, 0.2)\n",
            "  ELASTIC: False\n",
            "  ENABLE: True\n",
            "  E_ALPHA: (12, 16)\n",
            "  E_MODE: constant\n",
            "  E_SIGMA: 4\n",
            "  GAMMA_CONTRAST: False\n",
            "  GAUSSIAN_NOISE: False\n",
            "  GAUSSIAN_NOISE_MEAN: 0.0\n",
            "  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n",
            "  GAUSSIAN_NOISE_VAR: 0.05\n",
            "  GC_GAMMA: (1.25, 1.75)\n",
            "  GRAYSCALE: False\n",
            "  GRIDMASK: False\n",
            "  GRID_D_RANGE: (0.4, 1)\n",
            "  GRID_INVERT: False\n",
            "  GRID_RATIO: 0.6\n",
            "  GRID_ROTATE: 1.0\n",
            "  G_BLUR: False\n",
            "  G_SIGMA: (1.0, 2.0)\n",
            "  HFLIP: True\n",
            "  MB_KERNEL: (3, 7)\n",
            "  MEDIAN_BLUR: False\n",
            "  MISALIGNMENT: False\n",
            "  MISSING_SECTIONS: False\n",
            "  MISSP_ITERATIONS: (10, 30)\n",
            "  MOTB_K_RANGE: (8, 12)\n",
            "  MOTION_BLUR: False\n",
            "  MS_DISPLACEMENT: 16\n",
            "  MS_ROTATE_RATIO: 0.5\n",
            "  PEPPER: False\n",
            "  PEPPER_AMOUNT: 0.05\n",
            "  POISSON_NOISE: False\n",
            "  RANDOM_ROT: True\n",
            "  RANDOM_ROT_RANGE: (-180, 180)\n",
            "  ROT90: False\n",
            "  SALT: False\n",
            "  SALT_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER: False\n",
            "  SALT_AND_PEPPER_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER_PROP: 0.5\n",
            "  SHEAR: False\n",
            "  SHEAR_RANGE: (-20, 20)\n",
            "  SHIFT: False\n",
            "  SHIFT_RANGE: (0.1, 0.2)\n",
            "  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n",
            "  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n",
            "  VFLIP: True\n",
            "  ZFLIP: False\n",
            "  ZOOM: False\n",
            "  ZOOM_RANGE: (0.8, 1.2)\n",
            "DATA:\n",
            "  CHECK_GENERATORS: False\n",
            "  EXTRACT_RANDOM_PATCH: False\n",
            "  NORMALIZATION:\n",
            "    CUSTOM_MEAN: -1.0\n",
            "    CUSTOM_STD: -1.0\n",
            "    TYPE: div\n",
            "  PATCH_SIZE: (224, 224, 3)\n",
            "  PROBABILITY_MAP: False\n",
            "  REFLECT_TO_COMPLETE_SHAPE: False\n",
            "  TEST:\n",
            "    ARGMAX_TO_OUTPUT: False\n",
            "    BINARY_MASKS: /content/data/test/../bin_mask\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/test/y_detection_masks\n",
            "    GT_PATH: user_data/test/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/test_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/test/y_BC_thick\n",
            "    IN_MEMORY: False\n",
            "    LOAD_GT: False\n",
            "    MEDIAN_PADDING: False\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (0, 0)\n",
            "    PATH: /content/data/test\n",
            "    RESOLUTION: (1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/test_ssl_source\n",
            "    USE_VAL_AS_TEST: False\n",
            "  TRAIN:\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/train/y_detection_masks\n",
            "    GT_PATH: user_data/train/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/train/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    MINIMUM_FOREGROUND_PER: -1.0\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (0, 0)\n",
            "    PATH: /content/data/train\n",
            "    REPLICATE: 0\n",
            "    RESOLUTION: (1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train_ssl_source\n",
            "  VAL:\n",
            "    BINARY_MASKS: user_data/val/x/../bin_mask\n",
            "    CROSS_VAL: False\n",
            "    CROSS_VAL_FOLD: 1\n",
            "    CROSS_VAL_NFOLD: 5\n",
            "    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n",
            "    FROM_TRAIN: True\n",
            "    GT_PATH: user_data/val/y\n",
            "    INSTANCE_CHANNELS_DIR: user_data/val/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (0, 0)\n",
            "    PATH: user_data/val/x\n",
            "    RANDOM: True\n",
            "    RESOLUTION: (1, 1)\n",
            "    SPLIT_TRAIN: 0.5\n",
            "    SSL_SOURCE_DIR: user_data/val/x_ssl_source\n",
            "  W_BACKGROUND: 0.06\n",
            "  W_FOREGROUND: 0.94\n",
            "LOSS:\n",
            "  TYPE: CE\n",
            "MODEL:\n",
            "  ACTIVATION: elu\n",
            "  ARCHITECTURE: simple_cnn\n",
            "  BATCH_NORMALIZATION: False\n",
            "  DROPOUT_VALUES: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "  FEATURE_MAPS: [16, 32, 64, 128, 256]\n",
            "  KERNEL_INIT: he_normal\n",
            "  KERNEL_SIZE: 3\n",
            "  LAST_ACTIVATION: sigmoid\n",
            "  LOAD_CHECKPOINT: False\n",
            "  MAKE_PLOT: False\n",
            "  N_CLASSES: 75\n",
            "  SPATIAL_DROPOUT: False\n",
            "  TIRAMISU_DEPTH: 3\n",
            "  UNETR_DEC_ACTIVATION: relu\n",
            "  UNETR_DEC_KERNEL_INIT: he_normal\n",
            "  UNETR_VIT_HIDD_MULT: 3\n",
            "  UNETR_VIT_NUM_FILTERS: 16\n",
            "  UPSAMPLE_LAYER: convtranspose\n",
            "  VIT_HIDDEN_SIZE: 768\n",
            "  VIT_MLP_DIMS: 3072\n",
            "  VIT_NUM_HEADS: 12\n",
            "  VIT_NUM_LAYERS: 12\n",
            "  VIT_TOKEN_SIZE: 16\n",
            "  Z_DOWN: [0, 0, 0, 0]\n",
            "PATHS:\n",
            "  CHARTS: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/charts\n",
            "  CHECKPOINT: /content/output/my_2d_classification_but/checkpoints\n",
            "  CHECKPOINT_FILE: /content/output/my_2d_classification_but/checkpoints/model_weights_my_2d_classification_but_1.h5\n",
            "  DA_SAMPLES: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/aug\n",
            "  GEN_CHECKS: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/gen_check\n",
            "  GEN_MASK_CHECKS: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/gen_mask_check\n",
            "  MEAN_INFO_FILE: /content/output/my_2d_classification_but/checkpoints/normalization_mean_value.npy\n",
            "  PROB_MAP_DIR: /content/output/my_2d_classification_but/prob_map\n",
            "  PROB_MAP_FILENAME: prob_map.npy\n",
            "  PROFILER: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/profiler\n",
            "  RESULT_DIR:\n",
            "    AS_3D_STACK_POST_PROCESSING: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/as_3d_stack_post_processing\n",
            "    DET_ASSOC_POINTS: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/point_associations\n",
            "    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/per_image_local_max_check\n",
            "    FULL_IMAGE: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/full_image\n",
            "    FULL_IMAGE_BIN: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/full_image_binarized\n",
            "    INST_ASSOC_POINTS: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/instance_associations\n",
            "    PATH: /content/output/my_2d_classification_but/results/my_2d_classification_but_1\n",
            "    PER_IMAGE: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/per_image\n",
            "    PER_IMAGE_BIN: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/per_image_binarized\n",
            "    PER_IMAGE_INSTANCES: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/per_image_instances\n",
            "    PER_IMAGE_POST_PROCESSING: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/per_image_post_processing\n",
            "  STD_INFO_FILE: /content/output/my_2d_classification_but/checkpoints/normalization_std_value.npy\n",
            "  TEST_FULL_GT_H5: user_data/test/y/h5\n",
            "  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/test_BC_instance_channels\n",
            "  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/train_BC_instance_channels\n",
            "  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/val_BC_instance_channels\n",
            "  WATERSHED_DIR: /content/output/my_2d_classification_but/results/my_2d_classification_but_1/watershed\n",
            "PROBLEM:\n",
            "  DENOISING:\n",
            "    N2V_MANIPULATOR: uniform_withCP\n",
            "    N2V_NEIGHBORHOOD_RADIUS: 5\n",
            "    N2V_PERC_PIX: 0.198\n",
            "    N2V_STRUCTMASK: False\n",
            "  DETECTION:\n",
            "    CENTRAL_POINT_DILATION: 3\n",
            "    CHECK_POINTS_CREATED: True\n",
            "    DATA_CHECK_MW: True\n",
            "  INSTANCE_SEG:\n",
            "    DATA_CHANNELS: BC\n",
            "    DATA_CHANNEL_WEIGHTS: (1, 1)\n",
            "    DATA_CHECK_MW: True\n",
            "    DATA_CONTOUR_MODE: thick\n",
            "    DATA_MW_OPTIMIZE_THS: False\n",
            "    DATA_MW_TH_BINARY_MASK: 0.5\n",
            "    DATA_MW_TH_CONTOUR: 0.1\n",
            "    DATA_MW_TH_DISTANCE: 2.0\n",
            "    DATA_MW_TH_DIST_FOREGROUND: 1.2\n",
            "    DATA_MW_TH_FOREGROUND: 0.3\n",
            "    DATA_MW_TH_POINTS: 0.5\n",
            "    DATA_REMOVE_AFTER_MW: False\n",
            "    DATA_REMOVE_BEFORE_MW: False\n",
            "    DATA_REMOVE_SMALL_OBJ_AFTER: 100\n",
            "    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n",
            "    ERODE_AND_DILATE_FOREGROUND: False\n",
            "    FORE_DILATION_RADIUS: 5\n",
            "    FORE_EROSION_RADIUS: 5\n",
            "    SEED_MORPH_RADIUS: []\n",
            "    SEED_MORPH_SEQUENCE: []\n",
            "  NDIM: 2D\n",
            "  SELF_SUPERVISED:\n",
            "    NOISE: 0.2\n",
            "    PRETEXT_TASK: crappify\n",
            "    RESIZING_FACTOR: 4\n",
            "  SUPER_RESOLUTION:\n",
            "    UPSCALING: 1\n",
            "  TYPE: CLASSIFICATION\n",
            "SYSTEM:\n",
            "  NUM_CPUS: -1\n",
            "  SEED: 0\n",
            "TEST:\n",
            "  ANALIZE_2D_IMGS_AS_3D_STACK: False\n",
            "  AUGMENTATION: False\n",
            "  DET_LOCAL_MAX_COORDS: False\n",
            "  DET_MIN_TH_TO_BE_PEAK: [0.2]\n",
            "  DET_TOLERANCE: [10]\n",
            "  ENABLE: True\n",
            "  EVALUATE: True\n",
            "  MATCHING_SEGCOMPARE: False\n",
            "  MATCHING_STATS: True\n",
            "  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n",
            "  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n",
            "  POST_PROCESSING:\n",
            "    APPLY_MASK: False\n",
            "    DET_WATERSHED: False\n",
            "    DET_WATERSHED_DONUTS_CLASSES: [-1]\n",
            "    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n",
            "    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n",
            "    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n",
            "    REMOVE_CLOSE_POINTS: False\n",
            "    REMOVE_CLOSE_POINTS_RADIUS: [-1.0]\n",
            "    REPARE_LARGE_BLOBS_SIZE: -1\n",
            "    VORONOI_ON_MASK: False\n",
            "    VORONOI_TH: 0.0\n",
            "    WATERSHED_CIRCULARITY: -1.0\n",
            "    YZ_FILTERING: False\n",
            "    YZ_FILTERING_SIZE: 5\n",
            "    Z_FILTERING: False\n",
            "    Z_FILTERING_SIZE: 5\n",
            "  REDUCE_MEMORY: False\n",
            "  STATS:\n",
            "    FULL_IMG: True\n",
            "    MERGE_PATCHES: False\n",
            "    PER_PATCH: False\n",
            "  VERBOSE: True\n",
            "TRAIN:\n",
            "  BATCH_SIZE: 6\n",
            "  CHECKPOINT_MONITOR: val_loss\n",
            "  EARLYSTOPPING_MONITOR: val_loss\n",
            "  ENABLE: True\n",
            "  EPOCHS: 100\n",
            "  LR: 0.0001\n",
            "  LR_SCHEDULER:\n",
            "    MIN_LR: -1.0\n",
            "    NAME: \n",
            "    REDUCEONPLATEAU_FACTOR: 0.5\n",
            "    REDUCEONPLATEAU_PATIENCE: -1\n",
            "    WARMUP_COSINE_DECAY_EPOCHS: -1\n",
            "    WARMUP_COSINE_DECAY_HOLD_EPOCHS: -1\n",
            "    WARMUP_COSINE_DECAY_LR: -1.0\n",
            "  OPTIMIZER: ADAM\n",
            "  PATIENCE: 20\n",
            "  PROFILER: False\n",
            "  PROFILER_BATCH_RANGE: 10, 100\n",
            "  W_DECAY: 0.004\n",
            "####################\n",
            "#  PRE-PROCESSING  #\n",
            "####################\n",
            "\n",
            "#################\n",
            "#   LOAD DATA   #\n",
            "#################\n",
            "\n",
            "### LOAD ###\n",
            "Seems to be the first run as no data is prepared. Creating .npy files: /content/data/train/../npy_data_for_classification/X_train.npy\n",
            "## TRAIN ##\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/BiaPy/main.py\", line 87, in <module>\n",
            "    engine = Engine(cfg, job_identifier, num_gpus)\n",
            "  File \"/content/BiaPy/engine/engine.py\", line 133, in __init__\n",
            "    X_train, Y_train, X_val, Y_val = f_name(cfg)\n",
            "  File \"/content/BiaPy/data/data_2D_manipulation.py\", line 850, in load_data_classification\n",
            "    X_data = np.concatenate(X_data, 0)\n",
            "  File \"<__array_function__ internals>\", line 180, in concatenate\n",
            "ValueError: need at least one array to concatenate\n"
          ]
        }
      ]
    }
  ]
}