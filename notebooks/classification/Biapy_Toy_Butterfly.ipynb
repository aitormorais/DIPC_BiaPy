{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import pandas as pd\n",
        "def organizar_csv(ruta_csv,ruta_img,ruta_nueva):\n",
        "  # Carga los datos del csv\n",
        "  df = pd.read_csv(ruta_csv)\n",
        "\n",
        "  # Ubicación original de las imágenes\n",
        "  original_dir = ruta_img\n",
        "\n",
        "  # Directorio donde se almacenarán las imágenes organizadas\n",
        "  new_dir = ruta_nueva\n",
        "  # Crea el directorio si no existe\n",
        "  if not os.path.exists(new_dir):\n",
        "      os.makedirs(new_dir)\n",
        "\n",
        "  # Itera sobre todas las filas del dataframe\n",
        "  for index, row in df.iterrows():\n",
        "      # Consigue la etiqueta y el nombre del archivo\n",
        "      label = row['label']\n",
        "      filename = row['filename']\n",
        "\n",
        "      # Crea un nuevo directorio para la etiqueta si no existe\n",
        "      label_dir = os.path.join(new_dir, str(label))\n",
        "      if not os.path.exists(label_dir):\n",
        "          os.makedirs(label_dir)\n",
        "\n",
        "      # Copia la imagen al nuevo directorio\n",
        "      original_file_path = os.path.join(original_dir, filename)\n",
        "      new_file_path = os.path.join(label_dir, f'{index}.jpg')\n",
        "      shutil.copyfile(original_file_path, new_file_path)"
      ],
      "metadata": {
        "id": "8gqD2-ng70AG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2D Classification pipeline**\n",
        "___  \n",
        "  \n",
        "In this notebook we show how to apply a [BiaPy](https://biapy.readthedocs.io/en/latest/) pipeline for **2D classification** of butterfly data.\n",
        "\n",
        "**Without any coding**, we explain step by step how to\n",
        "1. **upload a set of training and test images** which need to be organized in folders, one for each class,\n",
        "2. **train a deep neural network (DNN)** model on the training set,\n",
        "3. **apply the model** to the test images, and\n",
        "4. **download the classification results** to your local machine.\n",
        "\n",
        "**Disclaimer:** The structure of the notebook is heavily inspired in the fantastic [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki).\n",
        "\n",
        "**Contact:** This notebook has been made by [Ignacio Arganda-Carreras](mailto:ignacio.arganda@ehu.eus) and [Daniel Franco-Barranco](mailto:daniel.franco@dipc.org). If you have any suggestion or comment, or find any problem, please write us an email or [create an issue in BiaPy's repository](https://github.com/danifranco/BiaPy/issues). Thanks!"
      ],
      "metadata": {
        "id": "RboAP3A4sXjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Expected inputs and outputs**\n",
        "___\n",
        "**Inputs**\n",
        "\n",
        "This notebook expects three folders as input:\n",
        "* **Training raw images**: with the raw 2D images to train the model.\n",
        "* **Test raw images**: with the raw 2D images to test the model.\n",
        "* **Output folder**: a path to store the classification results.\n",
        "\n",
        "**Outputs**\n",
        "\n",
        "If the execution is successful, a folder will be created containing the classification results. The resulting csv file can be downloaded at the end of the notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "RSsQsYfgs3kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prepare the environment**\n",
        "___\n",
        "\n",
        "Establish connection with Google services. You **must be logged in to Google** to continue.\n",
        "Since this is not Google's own code, you will probably see a message warning you of the dangers of running unfamiliar code. This is completely normal."
      ],
      "metadata": {
        "id": "q8zSRkZws8gR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download an example dataset**\n",
        "---\n",
        "If you do not have data at hand but would like to test the notebook, no worries! You can run the following cell to download an example dataset.\n",
        "\n",
        "In particular, we will use a particular subset of [Butterfly](https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification) dataset, concretely DermaMNIST dataset publicly available online."
      ],
      "metadata": {
        "id": "t98_DG_ntBop"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVxY_PZlq0WS",
        "outputId": "a0a9a5a8-cac6-41a8-a6e9-6386a41f0f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped under /content/data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/')\n",
        "#https://drive.google.com/file/d//view?usp=sharing\n",
        "!curl -L -s -o archive.zip 'https://drive.google.com/uc?id=1GBsn30dCC_XjGwtFLyMMhnAwTLFzW3vV&confirm=t'\n",
        "\n",
        "!unzip -q archive.zip\n",
        "!rm archive.zip\n",
        "\n",
        "print('Dataset downloaded and unzipped under /content')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Check for GPU access**\n",
        "---\n",
        "\n",
        "By default, the session should be using Python 3 and GPU acceleration, but it is possible to ensure that these are set properly by doing the following:\n",
        "\n",
        "Go to **Runtime -> Change the Runtime type**\n",
        "\n",
        "**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n",
        "\n",
        "**Accelerator: GPU** *(Graphics processing unit)*"
      ],
      "metadata": {
        "id": "FnWxdvZwt2Jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paths to load input images and save output files**\n",
        "___\n",
        "\n",
        "If option 1 (uploading the folder) or option 3 (downloading our prepared data samples) were chosen, define train_data_path as '/content/data/train', val_data_path as '/content/data/val' (if not using validation from train which can be ignored if so), test_data_path as '/content/data/test' and output_path as '/content/out'. Please make sure you download the results from the '/content/out' folder later!\n",
        "\n",
        "If option 2 is chosen, introduce here the paths to your input files and to the folder where you want to store the results. E.g. '/content/gdrive/MyDrive/...'.\n",
        "\n",
        "In case you have troubles finding the path to your folders, at the top left of this notebook you will find a small folder icon. Explore until you find the folders. There you can copy the folder path by right clicking and clicking \"copy\"."
      ],
      "metadata": {
        "id": "AkRkqEKIt54J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #####Path to train images\n",
        "train_data_path = '/content/data/train' #@param {type:\"string\"}\n",
        "#@markdown #####Path to validation images (necessary only if you do not want to extract validation from train, i.e. when **validation_from_train** variable below is **False**)\n",
        "val_data_path = '/content/data/train' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test images\n",
        "test_data_path = '/content/data/t_test' #@param {type:\"string\"}\n",
        "#@markdown #####Path to store the resulting images (it'll be created if not existing):\n",
        "output_path = '/content/output' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "ChY4nhTvt11i"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install BiaPy library**"
      ],
      "metadata": {
        "id": "QrAR4fbwuOhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Play to install BiaPy and its dependences\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.io import imread\n",
        "from skimage.exposure import match_histograms\n",
        "\n",
        "# Clone the repo\n",
        "os.chdir('/content/')\n",
        "if not os.path.exists('BiaPy'):\n",
        "    !git clone --depth 1 https://github.com/danifranco/BiaPy.git\n",
        "    !pip install --upgrade --no-cache-dir gdown &> /dev/null\n",
        "    sys.path.insert(0, 'BiaPy')\n",
        "    os.chdir('/content/BiaPy')\n",
        "\n",
        "    # Install dependencies\n",
        "    !pip install git+https://github.com/aleju/imgaug.git &> /dev/null\n",
        "    !pip install numpy_indexed yacs fill_voids edt &> /dev/null\n",
        "else:\n",
        "    print( 'Using existing installed version of BiaPy' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8cV2hSYuRQB",
        "outputId": "5c19f6b1-4642-4320-d9d2-8dcb25de7ab8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing installed version of BiaPy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Configure and train the DNN model**\n",
        "[BiaPy](https://biapy.readthedocs.io/en/latest/) contains a few deep learning models to perform classification.\n",
        "\n",
        "The selection of the model and the pipeline hyperparameters can be configured by editing the YAML configuration file or (easier) by running the next cell."
      ],
      "metadata": {
        "id": "N5XDAW20uc2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "organizar_csv('/content/Training_set.csv','/content/train', '/content/data/train')"
      ],
      "metadata": {
        "id": "hXSb7-ab8PGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Select your parameters**\n",
        "---\n",
        "#### **Name of the model**\n",
        "* **`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Avoid using the name of an existing model (saved in the same folder) as it will be overwritten.\n",
        "\n",
        "#### **Data management**\n",
        "\n",
        "* **`validation_from_train`:** Select to extract validation data from the training samples. If is not selected the validation data path must be set in **val_data_path** variable above.\n",
        "\n",
        "* **`percentage_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 10**\n",
        "\n",
        "* **`test_ground_truth`:** Select to use test data folder order as the ground truth class to measure the performance of the model's result. **Default value: True**\n",
        "\n",
        "#### **Basic training parameters**\n",
        "* **`number_of_classes`:** Input number of classes present in the problem. It must be equal to the number of subfolders in training and validation (if not extracted from train) folders.\n",
        "\n",
        "* **`number_of_epochs`:** Input how many epochs (rounds) the network will be trained. For the example dataset, reasonable results can already be observed after 100 epochs. **Default value: 100**\n",
        "\n",
        "* **`patience`:**  Input how many epochs you want to wait without the model improving its results in the validation set to stop training. **Default value: 20**\n",
        "\n",
        "#### **Advanced Parameters - experienced users only**\n",
        "* **`model_architecture`:**  Select the architecture of the DNN used as backbone of the pipeline. Options: EfficientNet B0 and a simple CNN. **Default value: EfficientNet B0**\n",
        "\n",
        "* **`batch_size:`** This parameter defines the number of patches seen in each training step. Reducing or increasing the **batch size** may slow or speed up your training, respectively, and can influence network performance. **Default value: 12**\n",
        "\n",
        "* **`patch_size`:** Input the size of the patches use to train your model (length in pixels in X and Y). The value should be smaller or equal to the dimensions of the image. **Default value: 28**\n",
        "\n",
        "* **`input_channels`:** Input the number of channels of your images (grayscale = 1, RGB = 3). **Default value: 3**\n",
        "\n",
        "* **`optimizer`:** Select the optimizer used to train your model. Options: ADAM, Stocastic Gradient Descent (SGD). ADAM converges usually faster but SGD is known for better generalization. **Default value: SGD**\n",
        "\n",
        "* **`initial_learning_rate`:** Input the initial value to be used as learning rate. If you select ADAM as optimizer, this value should be around 10e-4. **Default value: 0.001**"
      ],
      "metadata": {
        "id": "O75vmD4gugOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Name of the model:\n",
        "model_name = \"my_2d_classification_reduce\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Data management:\n",
        "validation_from_train = True #@param {type:\"boolean\"}\n",
        "percentage_validation =  10 #@param {type:\"number\"}\n",
        "test_ground_truth = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Basic training parameters:\n",
        "number_of_classes = 75#@param {type:\"number\"}\n",
        "number_of_epochs =  100#@param {type:\"number\"}\n",
        "patience =  20#@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Advanced training parameters:\n",
        "\n",
        "model_architecture = \"simple_cnn\" #@param [\"EfficientNetB0\", \"simple_cnn\"]\n",
        "\n",
        "batch_size =  32#@param {type:\"number\"}\n",
        "patch_size = 224 #@param {type:\"number\"}\n",
        "\n",
        "input_channels = 3 #@param {type:\"number\"}\n",
        "\n",
        "optimizer = \"ADAMW\" #@param [\"ADAM\", \"SGD\", \"ADAMW\"]\n",
        "initial_learning_rate = 0.001 #@param {type:\"number\"}"
      ],
      "metadata": {
        "id": "XAFIoaWZubrR"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Play to download the YAML configuration file and update it to train the model\n",
        "import errno\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# remove previous configuration file if it exists with the same name\n",
        "if os.path.exists( yaml_file ):\n",
        "    os.remove( yaml_file )\n",
        "\n",
        "# Download template file\n",
        "import shutil\n",
        "shutil.copy(\"/content/BiaPy/templates/classification/classification_2d.yaml\", yaml_file)\n",
        "\n",
        "# Check folders before modifying the .yaml file\n",
        "if not os.path.exists(train_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_data_path)\n",
        "ids = sorted(next(os.walk(train_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(train_data_path))\n",
        "\n",
        "if not os.path.exists(val_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), val_data_path)\n",
        "ids = sorted(next(os.walk(val_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(val_data_path))\n",
        "\n",
        "if not os.path.exists(test_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_data_path)\n",
        "ids = sorted(next(os.walk(test_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(test_data_path))\n",
        "\n",
        "\n",
        "# open template configuration file\n",
        "import yaml\n",
        "with open( yaml_file, 'r') as stream:\n",
        "    try:\n",
        "        biapy_config = yaml.safe_load(stream)\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)\n",
        "\n",
        "# update paths to data\n",
        "biapy_config['DATA']['TRAIN']['PATH'] = train_data_path\n",
        "biapy_config['DATA']['VAL']['PATH'] = val_data_path\n",
        "biapy_config['DATA']['TEST']['PATH'] = test_data_path\n",
        "biapy_config['DATA']['TEST']['LOAD_GT'] = test_ground_truth\n",
        "\n",
        "# update data patch size\n",
        "biapy_config['DATA']['PATCH_SIZE'] = '('+str(patch_size)+', '+ str(patch_size)+', ' + str(input_channels)+')'\n",
        "# adjust test padding accordingly\n",
        "padding = patch_size // 8\n",
        "biapy_config['DATA']['TEST']['PADDING'] = '('+str(padding)+', '+ str(padding)+')'\n",
        "\n",
        "# update training parameters\n",
        "biapy_config['DATA']['VAL']['FROM_TRAIN'] = validation_from_train\n",
        "biapy_config['DATA']['VAL']['SPLIT_TRAIN'] = percentage_validation/100.0\n",
        "biapy_config['TRAIN']['EPOCHS'] = number_of_epochs\n",
        "biapy_config['TRAIN']['PATIENCE'] = patience\n",
        "biapy_config['TRAIN']['BATCH_SIZE'] = batch_size\n",
        "biapy_config['TRAIN']['OPTIMIZER'] = optimizer\n",
        "biapy_config['TRAIN']['LR'] = initial_learning_rate\n",
        "\n",
        "# Transcribe model architecture\n",
        "# Available models: \"simple_cnn\", \"EfficientNetB0\"\n",
        "architecture = 'simple_cnn'\n",
        "if model_architecture == \"simple_cnn\":\n",
        "    architecture = 'simple_cnn'\n",
        "else:\n",
        "    architecture = 'EfficientNetB0'\n",
        "biapy_config['MODEL']['N_CLASSES'] = number_of_classes\n",
        "biapy_config['MODEL']['ARCHITECTURE'] = architecture\n",
        "\n",
        "# save file\n",
        "with open( yaml_file, 'w') as outfile:\n",
        "    yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Training configuration finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8uemuZM9iI3",
        "outputId": "2eb1a81d-a945-40ce-ade8-78f90f705d93"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training configuration finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def contar_imagenes_en_directorio(directorio):\n",
        "    contador = 0\n",
        "    extensiones_validas = ['.jpg', '.png', '.jpeg', '.gif']  # Puedes agregar más extensiones si es necesario\n",
        "\n",
        "    for carpeta, _, archivos in os.walk(directorio):\n",
        "        for archivo in archivos:\n",
        "            _, extension = os.path.splitext(archivo)\n",
        "            if extension.lower() in extensiones_validas:\n",
        "                contador += 1\n",
        "\n",
        "    return contador\n",
        "\n",
        "directorio = \"/content/data/train\"\n",
        "cantidad_imagenes = contar_imagenes_en_directorio(directorio)\n",
        "print(f\"El directorio '{directorio}' contiene {cantidad_imagenes} imágenes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsVAtm19FouF",
        "outputId": "58132b3e-7c37-4d1b-fa73-204307616cda"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El directorio '/content/data/train' contiene 2475 imágenes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def contar_imagenes_en_carpeta(carpeta):\n",
        "    contador = 0\n",
        "    extensiones_validas = ['.jpg', '.png', '.jpeg', '.gif']  # Puedes agregar más extensiones si es necesario\n",
        "\n",
        "    for archivo in os.listdir(carpeta):\n",
        "        _, extension = os.path.splitext(archivo)\n",
        "        if extension.lower() in extensiones_validas:\n",
        "            contador += 1\n",
        "\n",
        "    return contador\n",
        "\n",
        "directorio = \"/content/data/train\"\n",
        "\n",
        "for carpeta in os.listdir(directorio):\n",
        "    ruta_carpeta = os.path.join(directorio, carpeta)\n",
        "    if os.path.isdir(ruta_carpeta):\n",
        "        cantidad_imagenes = contar_imagenes_en_carpeta(ruta_carpeta)\n",
        "        print(f\"En la carpeta '{carpeta}' hay {cantidad_imagenes} imágenes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8u-WmNyF4sV",
        "outputId": "0738cea2-77cd-4b9c-9c4d-4b8abda3f4ab"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En la carpeta 'CHECQUERED SKIPPER' hay 95 imágenes.\n",
            "En la carpeta 'PURPLISH COPPER' hay 92 imágenes.\n",
            "En la carpeta 'BANDED PEACOCK' hay 83 imágenes.\n",
            "En la carpeta 'SCARCE SWALLOW' hay 97 imágenes.\n",
            "En la carpeta 'CLEOPATRA' hay 93 imágenes.\n",
            "En la carpeta 'CRECENT' hay 97 imágenes.\n",
            "En la carpeta 'ULYSES' hay 84 imágenes.\n",
            "En la carpeta 'RED SPOTTED PURPLE' hay 86 imágenes.\n",
            "En la carpeta 'PAINTED LADY' hay 78 imágenes.\n",
            "En la carpeta 'CHESTNUT' hay 85 imágenes.\n",
            "En la carpeta 'QUESTION MARK' hay 77 imágenes.\n",
            "En la carpeta 'SOOTYWING' hay 90 imágenes.\n",
            "En la carpeta 'COMMON BANDED AWL' hay 87 imágenes.\n",
            "En la carpeta 'IPHICLUS SISTER' hay 95 imágenes.\n",
            "En la carpeta 'ORCHARD SWALLOW' hay 76 imágenes.\n",
            "En la carpeta 'RED ADMIRAL' hay 82 imágenes.\n",
            "En la carpeta 'AN 88' hay 85 imágenes.\n",
            "En la carpeta 'PURPLE HAIRSTREAK' hay 79 imágenes.\n",
            "En la carpeta 'ORANGE OAKLEAF' hay 87 imágenes.\n",
            "En la carpeta 'LARGE MARBLE' hay 81 imágenes.\n",
            "En la carpeta 'RED CRACKER' hay 96 imágenes.\n",
            "En la carpeta 'MALACHITE' hay 73 imágenes.\n",
            "En la carpeta 'DANAID EGGFLY' hay 94 imágenes.\n",
            "En la carpeta 'SOUTHERN DOGFACE' hay 87 imágenes.\n",
            "En la carpeta 'EASTERN PINE ELFIN' hay 95 imágenes.\n",
            "En la carpeta 'BROWN SIPROETA' hay 99 imágenes.\n",
            "En la carpeta 'CABBAGE WHITE' hay 90 imágenes.\n",
            "En la carpeta 'APPOLLO' hay 90 imágenes.\n",
            "En la carpeta 'COMMON WOOD-NYMPH' hay 90 imágenes.\n",
            "En la carpeta 'MESTRA' hay 86 imágenes.\n",
            "En la carpeta 'EASTERN DAPPLE WHITE' hay 92 imágenes.\n",
            "En la carpeta 'GREAT EGGFLY' hay 78 imágenes.\n",
            "En la carpeta 'BLACK HAIRSTREAK' hay 85 imágenes.\n",
            "En la carpeta 'MANGROVE SKIPPER' hay 87 imágenes.\n",
            "En la carpeta 'MONARCH' hay 90 imágenes.\n",
            "En la carpeta 'ORANGE TIP' hay 96 imágenes.\n",
            "En la carpeta 'GOLD BANDED' hay 73 imágenes.\n",
            "En la carpeta 'MILBERTS TORTOISESHELL' hay 96 imágenes.\n",
            "En la carpeta 'CLOUDED SULPHUR' hay 92 imágenes.\n",
            "En la carpeta 'BANDED ORANGE HELICONIAN' hay 97 imágenes.\n",
            "En la carpeta 'GREEN CELLED CATTLEHEART' hay 88 imágenes.\n",
            "En la carpeta 'JULIA' hay 81 imágenes.\n",
            "En la carpeta 'SILVER SPOT SKIPPER' hay 83 imágenes.\n",
            "En la carpeta 'TWO BARRED FLASHER' hay 76 imágenes.\n",
            "En la carpeta 'PINE WHITE' hay 86 imágenes.\n",
            "En la carpeta 'COPPER TAIL' hay 94 imágenes.\n",
            "En la carpeta 'PEACOCK' hay 84 imágenes.\n",
            "En la carpeta 'SLEEPY ORANGE' hay 107 imágenes.\n",
            "En la carpeta 'PAPER KITE' hay 90 imágenes.\n",
            "En la carpeta 'WOOD SATYR' hay 71 imágenes.\n",
            "En la carpeta 'TROPICAL LEAFWING' hay 83 imágenes.\n",
            "En la carpeta 'VICEROY' hay 81 imágenes.\n",
            "En la carpeta 'AMERICAN SNOOT' hay 74 imágenes.\n",
            "En la carpeta 'BLUE SPOTTED CROW' hay 86 imágenes.\n",
            "En la carpeta 'AFRICAN GIANT SWALLOWTAIL' hay 75 imágenes.\n",
            "En la carpeta 'GREY HAIRSTREAK' hay 86 imágenes.\n",
            "En la carpeta 'CAIRNS BIRDWING' hay 83 imágenes.\n",
            "En la carpeta 'INDRA SWALLOW' hay 81 imágenes.\n",
            "En la carpeta 'GREAT JAY' hay 94 imágenes.\n",
            "En la carpeta 'ATALA' hay 100 imágenes.\n",
            "En la carpeta 'BECKERS WHITE' hay 81 imágenes.\n",
            "En la carpeta 'PIPEVINE SWALLOW' hay 84 imágenes.\n",
            "En la carpeta 'ZEBRA LONG WING' hay 76 imágenes.\n",
            "En la carpeta 'RED POSTMAN' hay 89 imágenes.\n",
            "En la carpeta 'ADONIS' hay 88 imágenes.\n",
            "En la carpeta 'BLUE MORPHO' hay 75 imágenes.\n",
            "En la carpeta 'ELBOWED PIERROT' hay 82 imágenes.\n",
            "En la carpeta 'YELLOW SWALLOW TAIL' hay 75 imágenes.\n",
            "En la carpeta 'POPINJAY' hay 85 imágenes.\n",
            "En la carpeta 'CLODIUS PARNASSIAN' hay 87 imágenes.\n",
            "En la carpeta 'STRAITED QUEEN' hay 87 imágenes.\n",
            "En la carpeta 'EASTERN COMA' hay 93 imágenes.\n",
            "En la carpeta 'CRIMSON PATCH' hay 72 imágenes.\n",
            "En la carpeta 'METALMARK' hay 76 imágenes.\n",
            "En la carpeta 'MOURNING CLOAK' hay 131 imágenes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def contar_imagenes_en_carpeta(carpeta):\n",
        "    contador = 0\n",
        "    extensiones_validas = ['.jpg', '.png', '.jpeg', '.gif']  # Puedes agregar más extensiones si es necesario\n",
        "\n",
        "    for archivo in os.listdir(carpeta):\n",
        "        _, extension = os.path.splitext(archivo)\n",
        "        if extension.lower() in extensiones_validas:\n",
        "            contador += 1\n",
        "\n",
        "    return contador\n",
        "\n",
        "def eliminar_imagenes_excedentes(carpeta, objetivo):\n",
        "    imagenes_actuales = contar_imagenes_en_carpeta(carpeta)\n",
        "    excedentes = imagenes_actuales - objetivo\n",
        "\n",
        "    if excedentes <= 0:\n",
        "        return\n",
        "\n",
        "    imagenes_a_eliminar = random.sample(os.listdir(carpeta), excedentes)\n",
        "    for imagen in imagenes_a_eliminar:\n",
        "        ruta_imagen = os.path.join(carpeta, imagen)\n",
        "        os.remove(ruta_imagen)\n",
        "\n",
        "directorio = \"/content/data/train\"\n",
        "objetivo_total_imagenes = 2500\n",
        "objetivo_por_carpeta = objetivo_total_imagenes // len(os.listdir(directorio))\n",
        "\n",
        "for carpeta in os.listdir(directorio):\n",
        "    ruta_carpeta = os.path.join(directorio, carpeta)\n",
        "    if os.path.isdir(ruta_carpeta):\n",
        "        eliminar_imagenes_excedentes(ruta_carpeta, objetivo_por_carpeta)\n",
        "\n",
        "cantidad_total_imagenes = sum(contar_imagenes_en_carpeta(os.path.join(directorio, carpeta)) for carpeta in os.listdir(directorio))\n",
        "print(f\"Se ha logrado un total de aproximadamente {cantidad_total_imagenes} imágenes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgrLCajuGabV",
        "outputId": "04a608f3-2f9c-4013-bbc8-01b8cd2a3801"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se ha logrado un total de aproximadamente 2475 imágenes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for carpeta in os.listdir(directorio):\n",
        "    ruta_carpeta = os.path.join(directorio, carpeta)\n",
        "    if os.path.isdir(ruta_carpeta):\n",
        "        cantidad_imagenes = contar_imagenes_en_carpeta(ruta_carpeta)\n",
        "        print(f\"En la carpeta '{carpeta}' hay {cantidad_imagenes} imágenes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6LicTavGgUd",
        "outputId": "caa0397d-5806-4b14-95c3-08ab912f2d8a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En la carpeta 'CHECQUERED SKIPPER' hay 33 imágenes.\n",
            "En la carpeta 'PURPLISH COPPER' hay 33 imágenes.\n",
            "En la carpeta 'BANDED PEACOCK' hay 33 imágenes.\n",
            "En la carpeta 'SCARCE SWALLOW' hay 33 imágenes.\n",
            "En la carpeta 'CLEOPATRA' hay 33 imágenes.\n",
            "En la carpeta 'CRECENT' hay 33 imágenes.\n",
            "En la carpeta 'ULYSES' hay 33 imágenes.\n",
            "En la carpeta 'RED SPOTTED PURPLE' hay 33 imágenes.\n",
            "En la carpeta 'PAINTED LADY' hay 33 imágenes.\n",
            "En la carpeta 'CHESTNUT' hay 33 imágenes.\n",
            "En la carpeta 'QUESTION MARK' hay 33 imágenes.\n",
            "En la carpeta 'SOOTYWING' hay 33 imágenes.\n",
            "En la carpeta 'COMMON BANDED AWL' hay 33 imágenes.\n",
            "En la carpeta 'IPHICLUS SISTER' hay 33 imágenes.\n",
            "En la carpeta 'ORCHARD SWALLOW' hay 33 imágenes.\n",
            "En la carpeta 'RED ADMIRAL' hay 33 imágenes.\n",
            "En la carpeta 'AN 88' hay 33 imágenes.\n",
            "En la carpeta 'PURPLE HAIRSTREAK' hay 33 imágenes.\n",
            "En la carpeta 'ORANGE OAKLEAF' hay 33 imágenes.\n",
            "En la carpeta 'LARGE MARBLE' hay 33 imágenes.\n",
            "En la carpeta 'RED CRACKER' hay 33 imágenes.\n",
            "En la carpeta 'MALACHITE' hay 33 imágenes.\n",
            "En la carpeta 'DANAID EGGFLY' hay 33 imágenes.\n",
            "En la carpeta 'SOUTHERN DOGFACE' hay 33 imágenes.\n",
            "En la carpeta 'EASTERN PINE ELFIN' hay 33 imágenes.\n",
            "En la carpeta 'BROWN SIPROETA' hay 33 imágenes.\n",
            "En la carpeta 'CABBAGE WHITE' hay 33 imágenes.\n",
            "En la carpeta 'APPOLLO' hay 33 imágenes.\n",
            "En la carpeta 'COMMON WOOD-NYMPH' hay 33 imágenes.\n",
            "En la carpeta 'MESTRA' hay 33 imágenes.\n",
            "En la carpeta 'EASTERN DAPPLE WHITE' hay 33 imágenes.\n",
            "En la carpeta 'GREAT EGGFLY' hay 33 imágenes.\n",
            "En la carpeta 'BLACK HAIRSTREAK' hay 33 imágenes.\n",
            "En la carpeta 'MANGROVE SKIPPER' hay 33 imágenes.\n",
            "En la carpeta 'MONARCH' hay 33 imágenes.\n",
            "En la carpeta 'ORANGE TIP' hay 33 imágenes.\n",
            "En la carpeta 'GOLD BANDED' hay 33 imágenes.\n",
            "En la carpeta 'MILBERTS TORTOISESHELL' hay 33 imágenes.\n",
            "En la carpeta 'CLOUDED SULPHUR' hay 33 imágenes.\n",
            "En la carpeta 'BANDED ORANGE HELICONIAN' hay 33 imágenes.\n",
            "En la carpeta 'GREEN CELLED CATTLEHEART' hay 33 imágenes.\n",
            "En la carpeta 'JULIA' hay 33 imágenes.\n",
            "En la carpeta 'SILVER SPOT SKIPPER' hay 33 imágenes.\n",
            "En la carpeta 'TWO BARRED FLASHER' hay 33 imágenes.\n",
            "En la carpeta 'PINE WHITE' hay 33 imágenes.\n",
            "En la carpeta 'COPPER TAIL' hay 33 imágenes.\n",
            "En la carpeta 'PEACOCK' hay 33 imágenes.\n",
            "En la carpeta 'SLEEPY ORANGE' hay 33 imágenes.\n",
            "En la carpeta 'PAPER KITE' hay 33 imágenes.\n",
            "En la carpeta 'WOOD SATYR' hay 33 imágenes.\n",
            "En la carpeta 'TROPICAL LEAFWING' hay 33 imágenes.\n",
            "En la carpeta 'VICEROY' hay 33 imágenes.\n",
            "En la carpeta 'AMERICAN SNOOT' hay 33 imágenes.\n",
            "En la carpeta 'BLUE SPOTTED CROW' hay 33 imágenes.\n",
            "En la carpeta 'AFRICAN GIANT SWALLOWTAIL' hay 33 imágenes.\n",
            "En la carpeta 'GREY HAIRSTREAK' hay 33 imágenes.\n",
            "En la carpeta 'CAIRNS BIRDWING' hay 33 imágenes.\n",
            "En la carpeta 'INDRA SWALLOW' hay 33 imágenes.\n",
            "En la carpeta 'GREAT JAY' hay 33 imágenes.\n",
            "En la carpeta 'ATALA' hay 33 imágenes.\n",
            "En la carpeta 'BECKERS WHITE' hay 33 imágenes.\n",
            "En la carpeta 'PIPEVINE SWALLOW' hay 33 imágenes.\n",
            "En la carpeta 'ZEBRA LONG WING' hay 33 imágenes.\n",
            "En la carpeta 'RED POSTMAN' hay 33 imágenes.\n",
            "En la carpeta 'ADONIS' hay 33 imágenes.\n",
            "En la carpeta 'BLUE MORPHO' hay 33 imágenes.\n",
            "En la carpeta 'ELBOWED PIERROT' hay 33 imágenes.\n",
            "En la carpeta 'YELLOW SWALLOW TAIL' hay 33 imágenes.\n",
            "En la carpeta 'POPINJAY' hay 33 imágenes.\n",
            "En la carpeta 'CLODIUS PARNASSIAN' hay 33 imágenes.\n",
            "En la carpeta 'STRAITED QUEEN' hay 33 imágenes.\n",
            "En la carpeta 'EASTERN COMA' hay 33 imágenes.\n",
            "En la carpeta 'CRIMSON PATCH' hay 33 imágenes.\n",
            "En la carpeta 'METALMARK' hay 33 imágenes.\n",
            "En la carpeta 'MOURNING CLOAK' hay 33 imágenes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Play to train the model\n",
        "\n",
        "import os\n",
        "import errno\n",
        "\n",
        "# Run the code\n",
        "os.chdir('/content/BiaPy')\n",
        "!python -u main.py --config '/content/'{job_name}'.yaml' --result_dir {output_path} --name {job_name} --run_id 1 --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao0NDdReCaxW",
        "outputId": "4f236a03-8541-4e82-c277-55d3a322e81e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date: 2023-07-27 11:29:10\n",
            "Arguments: Namespace(config='/content/my_2d_classification_reduce.yaml', result_dir='/content/output', name='my_2d_classification_reduce', run_id=1, gpu='0')\n",
            "Job: my_2d_classification_reduce_1\n",
            "Python       : 3.10.6 (main, May 29 2023, 11:10:38) [GCC 11.3.0]\n",
            "Keras        : 2.12.0\n",
            "Tensorflow   : 2.12.0\n",
            "Num GPUs Available:  0\n",
            "Configuration details:\n",
            "AUGMENTOR:\n",
            "  AFFINE_MODE: constant\n",
            "  AUG_NUM_SAMPLES: 10\n",
            "  AUG_SAMPLES: True\n",
            "  BRIGHTNESS: False\n",
            "  BRIGHTNESS_EM: False\n",
            "  BRIGHTNESS_EM_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_EM_MODE: 3D\n",
            "  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_MODE: 3D\n",
            "  CBLUR_DOWN_RANGE: (2, 8)\n",
            "  CBLUR_INSIDE: True\n",
            "  CBLUR_SIZE: (0.2, 0.4)\n",
            "  CHANNEL_SHUFFLE: False\n",
            "  CMIX_SIZE: (0.2, 0.4)\n",
            "  CNOISE_NB_ITERATIONS: (1, 3)\n",
            "  CNOISE_SCALE: (0.05, 0.1)\n",
            "  CNOISE_SIZE: (0.2, 0.4)\n",
            "  CONTRAST: False\n",
            "  CONTRAST_EM: False\n",
            "  CONTRAST_EM_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_EM_MODE: 3D\n",
            "  CONTRAST_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_MODE: 3D\n",
            "  COUT_APPLY_TO_MASK: False\n",
            "  COUT_CVAL: 0.0\n",
            "  COUT_NB_ITERATIONS: (1, 3)\n",
            "  COUT_SIZE: (0.05, 0.3)\n",
            "  CUTBLUR: False\n",
            "  CUTMIX: False\n",
            "  CUTNOISE: False\n",
            "  CUTOUT: False\n",
            "  DA_PROB: 0.5\n",
            "  DRAW_GRID: True\n",
            "  DROPOUT: False\n",
            "  DROP_RANGE: (0, 0.2)\n",
            "  ELASTIC: False\n",
            "  ENABLE: True\n",
            "  E_ALPHA: (12, 16)\n",
            "  E_MODE: constant\n",
            "  E_SIGMA: 4\n",
            "  GAMMA_CONTRAST: False\n",
            "  GAUSSIAN_NOISE: False\n",
            "  GAUSSIAN_NOISE_MEAN: 0.0\n",
            "  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n",
            "  GAUSSIAN_NOISE_VAR: 0.05\n",
            "  GC_GAMMA: (1.25, 1.75)\n",
            "  GRAYSCALE: False\n",
            "  GRIDMASK: False\n",
            "  GRID_D_RANGE: (0.4, 1)\n",
            "  GRID_INVERT: False\n",
            "  GRID_RATIO: 0.6\n",
            "  GRID_ROTATE: 1.0\n",
            "  G_BLUR: False\n",
            "  G_SIGMA: (1.0, 2.0)\n",
            "  HFLIP: True\n",
            "  MB_KERNEL: (3, 7)\n",
            "  MEDIAN_BLUR: False\n",
            "  MISALIGNMENT: False\n",
            "  MISSING_SECTIONS: False\n",
            "  MISSP_ITERATIONS: (10, 30)\n",
            "  MOTB_K_RANGE: (8, 12)\n",
            "  MOTION_BLUR: False\n",
            "  MS_DISPLACEMENT: 16\n",
            "  MS_ROTATE_RATIO: 0.5\n",
            "  PEPPER: False\n",
            "  PEPPER_AMOUNT: 0.05\n",
            "  POISSON_NOISE: False\n",
            "  RANDOM_ROT: True\n",
            "  RANDOM_ROT_RANGE: (-180, 180)\n",
            "  ROT90: False\n",
            "  SALT: False\n",
            "  SALT_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER: False\n",
            "  SALT_AND_PEPPER_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER_PROP: 0.5\n",
            "  SHEAR: False\n",
            "  SHEAR_RANGE: (-20, 20)\n",
            "  SHIFT: False\n",
            "  SHIFT_RANGE: (0.1, 0.2)\n",
            "  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n",
            "  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n",
            "  VFLIP: True\n",
            "  ZFLIP: False\n",
            "  ZOOM: False\n",
            "  ZOOM_RANGE: (0.8, 1.2)\n",
            "DATA:\n",
            "  CHECK_GENERATORS: False\n",
            "  EXTRACT_RANDOM_PATCH: False\n",
            "  NORMALIZATION:\n",
            "    CUSTOM_MEAN: -1.0\n",
            "    CUSTOM_STD: -1.0\n",
            "    TYPE: div\n",
            "  PATCH_SIZE: (224, 224, 3)\n",
            "  PROBABILITY_MAP: False\n",
            "  REFLECT_TO_COMPLETE_SHAPE: False\n",
            "  TEST:\n",
            "    ARGMAX_TO_OUTPUT: False\n",
            "    BINARY_MASKS: /content/data/t_test/../bin_mask\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/test/y_detection_masks\n",
            "    GT_PATH: user_data/test/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/t_test_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/test/y_BC_thick\n",
            "    IN_MEMORY: False\n",
            "    LOAD_GT: False\n",
            "    MEDIAN_PADDING: False\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (28, 28)\n",
            "    PATH: /content/data/t_test\n",
            "    RESOLUTION: (1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/t_test_ssl_source\n",
            "    USE_VAL_AS_TEST: False\n",
            "  TRAIN:\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/train/y_detection_masks\n",
            "    GT_PATH: user_data/train/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/train/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    MINIMUM_FOREGROUND_PER: -1.0\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (0, 0)\n",
            "    PATH: /content/data/train\n",
            "    REPLICATE: 0\n",
            "    RESOLUTION: (1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train_ssl_source\n",
            "  VAL:\n",
            "    BINARY_MASKS: /content/data/train/../bin_mask\n",
            "    CROSS_VAL: False\n",
            "    CROSS_VAL_FOLD: 1\n",
            "    CROSS_VAL_NFOLD: 5\n",
            "    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n",
            "    FROM_TRAIN: True\n",
            "    GT_PATH: user_data/val/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (0, 0)\n",
            "    PATH: /content/data/train\n",
            "    RANDOM: True\n",
            "    RESOLUTION: (1, 1)\n",
            "    SPLIT_TRAIN: 0.1\n",
            "    SSL_SOURCE_DIR: /content/data/train_ssl_source\n",
            "  W_BACKGROUND: 0.06\n",
            "  W_FOREGROUND: 0.94\n",
            "LOSS:\n",
            "  TYPE: CE\n",
            "MODEL:\n",
            "  ACTIVATION: elu\n",
            "  ARCHITECTURE: simple_cnn\n",
            "  BATCH_NORMALIZATION: False\n",
            "  DROPOUT_VALUES: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "  FEATURE_MAPS: [16, 32, 64, 128, 256]\n",
            "  KERNEL_INIT: he_normal\n",
            "  KERNEL_SIZE: 3\n",
            "  LAST_ACTIVATION: sigmoid\n",
            "  LOAD_CHECKPOINT: False\n",
            "  MAKE_PLOT: False\n",
            "  N_CLASSES: 75\n",
            "  SPATIAL_DROPOUT: False\n",
            "  TIRAMISU_DEPTH: 3\n",
            "  UNETR_DEC_ACTIVATION: relu\n",
            "  UNETR_DEC_KERNEL_INIT: he_normal\n",
            "  UNETR_VIT_HIDD_MULT: 3\n",
            "  UNETR_VIT_NUM_FILTERS: 16\n",
            "  UPSAMPLE_LAYER: convtranspose\n",
            "  VIT_HIDDEN_SIZE: 768\n",
            "  VIT_MLP_DIMS: 3072\n",
            "  VIT_NUM_HEADS: 12\n",
            "  VIT_NUM_LAYERS: 12\n",
            "  VIT_TOKEN_SIZE: 16\n",
            "  Z_DOWN: [0, 0, 0, 0]\n",
            "PATHS:\n",
            "  CHARTS: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/charts\n",
            "  CHECKPOINT: /content/output/my_2d_classification_reduce/checkpoints\n",
            "  CHECKPOINT_FILE: /content/output/my_2d_classification_reduce/checkpoints/model_weights_my_2d_classification_reduce_1.h5\n",
            "  DA_SAMPLES: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/aug\n",
            "  GEN_CHECKS: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/gen_check\n",
            "  GEN_MASK_CHECKS: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/gen_mask_check\n",
            "  MEAN_INFO_FILE: /content/output/my_2d_classification_reduce/checkpoints/normalization_mean_value.npy\n",
            "  PROB_MAP_DIR: /content/output/my_2d_classification_reduce/prob_map\n",
            "  PROB_MAP_FILENAME: prob_map.npy\n",
            "  PROFILER: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/profiler\n",
            "  RESULT_DIR:\n",
            "    AS_3D_STACK_POST_PROCESSING: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/as_3d_stack_post_processing\n",
            "    DET_ASSOC_POINTS: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/point_associations\n",
            "    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/per_image_local_max_check\n",
            "    FULL_IMAGE: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/full_image\n",
            "    FULL_IMAGE_BIN: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/full_image_binarized\n",
            "    INST_ASSOC_POINTS: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/instance_associations\n",
            "    PATH: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1\n",
            "    PER_IMAGE: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/per_image\n",
            "    PER_IMAGE_BIN: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/per_image_binarized\n",
            "    PER_IMAGE_INSTANCES: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/per_image_instances\n",
            "    PER_IMAGE_POST_PROCESSING: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/per_image_post_processing\n",
            "  STD_INFO_FILE: /content/output/my_2d_classification_reduce/checkpoints/normalization_std_value.npy\n",
            "  TEST_FULL_GT_H5: user_data/test/y/h5\n",
            "  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/test_BC_instance_channels\n",
            "  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/train_BC_instance_channels\n",
            "  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/val_BC_instance_channels\n",
            "  WATERSHED_DIR: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/watershed\n",
            "PROBLEM:\n",
            "  DENOISING:\n",
            "    N2V_MANIPULATOR: uniform_withCP\n",
            "    N2V_NEIGHBORHOOD_RADIUS: 5\n",
            "    N2V_PERC_PIX: 0.198\n",
            "    N2V_STRUCTMASK: False\n",
            "  DETECTION:\n",
            "    CENTRAL_POINT_DILATION: 3\n",
            "    CHECK_POINTS_CREATED: True\n",
            "    DATA_CHECK_MW: True\n",
            "  INSTANCE_SEG:\n",
            "    DATA_CHANNELS: BC\n",
            "    DATA_CHANNEL_WEIGHTS: (1, 1)\n",
            "    DATA_CHECK_MW: True\n",
            "    DATA_CONTOUR_MODE: thick\n",
            "    DATA_MW_OPTIMIZE_THS: False\n",
            "    DATA_MW_TH_BINARY_MASK: 0.5\n",
            "    DATA_MW_TH_CONTOUR: 0.1\n",
            "    DATA_MW_TH_DISTANCE: 2.0\n",
            "    DATA_MW_TH_DIST_FOREGROUND: 1.2\n",
            "    DATA_MW_TH_FOREGROUND: 0.3\n",
            "    DATA_MW_TH_POINTS: 0.5\n",
            "    DATA_REMOVE_AFTER_MW: False\n",
            "    DATA_REMOVE_BEFORE_MW: False\n",
            "    DATA_REMOVE_SMALL_OBJ_AFTER: 100\n",
            "    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n",
            "    ERODE_AND_DILATE_FOREGROUND: False\n",
            "    FORE_DILATION_RADIUS: 5\n",
            "    FORE_EROSION_RADIUS: 5\n",
            "    SEED_MORPH_RADIUS: []\n",
            "    SEED_MORPH_SEQUENCE: []\n",
            "  NDIM: 2D\n",
            "  SELF_SUPERVISED:\n",
            "    NOISE: 0.2\n",
            "    PRETEXT_TASK: crappify\n",
            "    RESIZING_FACTOR: 4\n",
            "  SUPER_RESOLUTION:\n",
            "    UPSCALING: 1\n",
            "  TYPE: CLASSIFICATION\n",
            "SYSTEM:\n",
            "  NUM_CPUS: -1\n",
            "  SEED: 0\n",
            "TEST:\n",
            "  ANALIZE_2D_IMGS_AS_3D_STACK: False\n",
            "  AUGMENTATION: False\n",
            "  DET_LOCAL_MAX_COORDS: False\n",
            "  DET_MIN_TH_TO_BE_PEAK: [0.2]\n",
            "  DET_TOLERANCE: [10]\n",
            "  ENABLE: True\n",
            "  EVALUATE: True\n",
            "  MATCHING_SEGCOMPARE: False\n",
            "  MATCHING_STATS: True\n",
            "  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n",
            "  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n",
            "  POST_PROCESSING:\n",
            "    APPLY_MASK: False\n",
            "    DET_WATERSHED: False\n",
            "    DET_WATERSHED_DONUTS_CLASSES: [-1]\n",
            "    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n",
            "    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n",
            "    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n",
            "    REMOVE_CLOSE_POINTS: False\n",
            "    REMOVE_CLOSE_POINTS_RADIUS: [-1.0]\n",
            "    REPARE_LARGE_BLOBS_SIZE: -1\n",
            "    VORONOI_ON_MASK: False\n",
            "    VORONOI_TH: 0.0\n",
            "    WATERSHED_CIRCULARITY: -1.0\n",
            "    YZ_FILTERING: False\n",
            "    YZ_FILTERING_SIZE: 5\n",
            "    Z_FILTERING: False\n",
            "    Z_FILTERING_SIZE: 5\n",
            "  REDUCE_MEMORY: False\n",
            "  STATS:\n",
            "    FULL_IMG: True\n",
            "    MERGE_PATCHES: False\n",
            "    PER_PATCH: False\n",
            "  VERBOSE: True\n",
            "TRAIN:\n",
            "  BATCH_SIZE: 32\n",
            "  CHECKPOINT_MONITOR: val_loss\n",
            "  EARLYSTOPPING_MONITOR: val_loss\n",
            "  ENABLE: True\n",
            "  EPOCHS: 100\n",
            "  LR: 0.001\n",
            "  LR_SCHEDULER:\n",
            "    MIN_LR: -1.0\n",
            "    NAME: \n",
            "    REDUCEONPLATEAU_FACTOR: 0.5\n",
            "    REDUCEONPLATEAU_PATIENCE: -1\n",
            "    WARMUP_COSINE_DECAY_EPOCHS: -1\n",
            "    WARMUP_COSINE_DECAY_HOLD_EPOCHS: -1\n",
            "    WARMUP_COSINE_DECAY_LR: -1.0\n",
            "  OPTIMIZER: ADAMW\n",
            "  PATIENCE: 20\n",
            "  PROFILER: False\n",
            "  PROFILER_BATCH_RANGE: 10, 100\n",
            "  W_DECAY: 0.004\n",
            "####################\n",
            "#  PRE-PROCESSING  #\n",
            "####################\n",
            "\n",
            "#################\n",
            "#   LOAD DATA   #\n",
            "#################\n",
            "\n",
            "### LOAD ###\n",
            "*** Loaded train data shape is: (5849, 224, 224, 3)\n",
            "*** Loaded validation data shape is: (650, 224, 224, 3)\n",
            "### END LOAD ###\n",
            "### LOAD ###\n",
            "*** Loaded test data shape is: (2786, 224, 224, 3)\n",
            "########################\n",
            "#  PREPARE GENERATORS  #\n",
            "########################\n",
            "\n",
            "Initializing train data generator . . .\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}