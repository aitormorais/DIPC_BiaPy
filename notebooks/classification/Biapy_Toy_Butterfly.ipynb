{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import pandas as pd\n",
        "def organizar_csv(ruta_csv,ruta_img,ruta_nueva):\n",
        "  # Carga los datos del csv\n",
        "  df = pd.read_csv(ruta_csv)\n",
        "\n",
        "  # Ubicaci칩n original de las im치genes\n",
        "  original_dir = ruta_img\n",
        "\n",
        "  # Directorio donde se almacenar치n las im치genes organizadas\n",
        "  new_dir = ruta_nueva\n",
        "  # Crea el directorio si no existe\n",
        "  if not os.path.exists(new_dir):\n",
        "      os.makedirs(new_dir)\n",
        "\n",
        "  # Itera sobre todas las filas del dataframe\n",
        "  for index, row in df.iterrows():\n",
        "      # Consigue la etiqueta y el nombre del archivo\n",
        "      label = row['label']\n",
        "      filename = row['filename']\n",
        "\n",
        "      # Crea un nuevo directorio para la etiqueta si no existe\n",
        "      label_dir = os.path.join(new_dir, str(label))\n",
        "      if not os.path.exists(label_dir):\n",
        "          os.makedirs(label_dir)\n",
        "\n",
        "      # Copia la imagen al nuevo directorio\n",
        "      original_file_path = os.path.join(original_dir, filename)\n",
        "      new_file_path = os.path.join(label_dir, f'{index}.jpg')\n",
        "      shutil.copyfile(original_file_path, new_file_path)"
      ],
      "metadata": {
        "id": "8gqD2-ng70AG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2D Classification pipeline**\n",
        "___  \n",
        "  \n",
        "In this notebook we show how to apply a [BiaPy](https://biapy.readthedocs.io/en/latest/) pipeline for **2D classification** of butterfly data.\n",
        "\n",
        "**Without any coding**, we explain step by step how to\n",
        "1. **upload a set of training and test images** which need to be organized in folders, one for each class,\n",
        "2. **train a deep neural network (DNN)** model on the training set,\n",
        "3. **apply the model** to the test images, and\n",
        "4. **download the classification results** to your local machine.\n",
        "\n",
        "**Disclaimer:** The structure of the notebook is heavily inspired in the fantastic [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki).\n",
        "\n",
        "**Contact:** This notebook has been made by [Ignacio Arganda-Carreras](mailto:ignacio.arganda@ehu.eus) and [Daniel Franco-Barranco](mailto:daniel.franco@dipc.org). If you have any suggestion or comment, or find any problem, please write us an email or [create an issue in BiaPy's repository](https://github.com/danifranco/BiaPy/issues). Thanks!"
      ],
      "metadata": {
        "id": "RboAP3A4sXjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Expected inputs and outputs**\n",
        "___\n",
        "**Inputs**\n",
        "\n",
        "This notebook expects three folders as input:\n",
        "* **Training raw images**: with the raw 2D images to train the model.\n",
        "* **Test raw images**: with the raw 2D images to test the model.\n",
        "* **Output folder**: a path to store the classification results.\n",
        "\n",
        "**Outputs**\n",
        "\n",
        "If the execution is successful, a folder will be created containing the classification results. The resulting csv file can be downloaded at the end of the notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "RSsQsYfgs3kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prepare the environment**\n",
        "___\n",
        "\n",
        "Establish connection with Google services. You **must be logged in to Google** to continue.\n",
        "Since this is not Google's own code, you will probably see a message warning you of the dangers of running unfamiliar code. This is completely normal."
      ],
      "metadata": {
        "id": "q8zSRkZws8gR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download an example dataset**\n",
        "---\n",
        "If you do not have data at hand but would like to test the notebook, no worries! You can run the following cell to download an example dataset.\n",
        "\n",
        "In particular, we will use a particular subset of [Butterfly](https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification) dataset, concretely DermaMNIST dataset publicly available online."
      ],
      "metadata": {
        "id": "t98_DG_ntBop"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVxY_PZlq0WS",
        "outputId": "a0a9a5a8-cac6-41a8-a6e9-6386a41f0f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped under /content/data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/')\n",
        "#https://drive.google.com/file/d//view?usp=sharing\n",
        "!curl -L -s -o archive.zip 'https://drive.google.com/uc?id=1GBsn30dCC_XjGwtFLyMMhnAwTLFzW3vV&confirm=t'\n",
        "\n",
        "!unzip -q archive.zip\n",
        "!rm archive.zip\n",
        "\n",
        "print('Dataset downloaded and unzipped under /content')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Check for GPU access**\n",
        "---\n",
        "\n",
        "By default, the session should be using Python 3 and GPU acceleration, but it is possible to ensure that these are set properly by doing the following:\n",
        "\n",
        "Go to **Runtime -> Change the Runtime type**\n",
        "\n",
        "**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n",
        "\n",
        "**Accelerator: GPU** *(Graphics processing unit)*"
      ],
      "metadata": {
        "id": "FnWxdvZwt2Jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paths to load input images and save output files**\n",
        "___\n",
        "\n",
        "If option 1 (uploading the folder) or option 3 (downloading our prepared data samples) were chosen, define train_data_path as '/content/data/train', val_data_path as '/content/data/val' (if not using validation from train which can be ignored if so), test_data_path as '/content/data/test' and output_path as '/content/out'. Please make sure you download the results from the '/content/out' folder later!\n",
        "\n",
        "If option 2 is chosen, introduce here the paths to your input files and to the folder where you want to store the results. E.g. '/content/gdrive/MyDrive/...'.\n",
        "\n",
        "In case you have troubles finding the path to your folders, at the top left of this notebook you will find a small folder icon. Explore until you find the folders. There you can copy the folder path by right clicking and clicking \"copy\"."
      ],
      "metadata": {
        "id": "AkRkqEKIt54J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #####Path to train images\n",
        "train_data_path = '/content/data/train' #@param {type:\"string\"}\n",
        "#@markdown #####Path to validation images (necessary only if you do not want to extract validation from train, i.e. when **validation_from_train** variable below is **False**)\n",
        "val_data_path = '/content/data/train' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test images\n",
        "test_data_path = '/content/data/t_test' #@param {type:\"string\"}\n",
        "#@markdown #####Path to store the resulting images (it'll be created if not existing):\n",
        "output_path = '/content/output' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "ChY4nhTvt11i"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install BiaPy library**"
      ],
      "metadata": {
        "id": "QrAR4fbwuOhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Play to install BiaPy and its dependences\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.io import imread\n",
        "from skimage.exposure import match_histograms\n",
        "\n",
        "# Clone the repo\n",
        "os.chdir('/content/')\n",
        "if not os.path.exists('BiaPy'):\n",
        "    !git clone --depth 1 https://github.com/danifranco/BiaPy.git\n",
        "    !pip install --upgrade --no-cache-dir gdown &> /dev/null\n",
        "    sys.path.insert(0, 'BiaPy')\n",
        "    os.chdir('/content/BiaPy')\n",
        "\n",
        "    # Install dependencies\n",
        "    !pip install git+https://github.com/aleju/imgaug.git &> /dev/null\n",
        "    !pip install numpy_indexed yacs fill_voids edt &> /dev/null\n",
        "else:\n",
        "    print( 'Using existing installed version of BiaPy' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8cV2hSYuRQB",
        "outputId": "5c19f6b1-4642-4320-d9d2-8dcb25de7ab8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing installed version of BiaPy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Configure and train the DNN model**\n",
        "[BiaPy](https://biapy.readthedocs.io/en/latest/) contains a few deep learning models to perform classification.\n",
        "\n",
        "The selection of the model and the pipeline hyperparameters can be configured by editing the YAML configuration file or (easier) by running the next cell."
      ],
      "metadata": {
        "id": "N5XDAW20uc2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "organizar_csv('/content/Training_set.csv','/content/train', '/content/data/train')"
      ],
      "metadata": {
        "id": "hXSb7-ab8PGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Select your parameters**\n",
        "---\n",
        "#### **Name of the model**\n",
        "* **`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Avoid using the name of an existing model (saved in the same folder) as it will be overwritten.\n",
        "\n",
        "#### **Data management**\n",
        "\n",
        "* **`validation_from_train`:** Select to extract validation data from the training samples. If is not selected the validation data path must be set in **val_data_path** variable above.\n",
        "\n",
        "* **`percentage_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 10**\n",
        "\n",
        "* **`test_ground_truth`:** Select to use test data folder order as the ground truth class to measure the performance of the model's result. **Default value: True**\n",
        "\n",
        "#### **Basic training parameters**\n",
        "* **`number_of_classes`:** Input number of classes present in the problem. It must be equal to the number of subfolders in training and validation (if not extracted from train) folders.\n",
        "\n",
        "* **`number_of_epochs`:** Input how many epochs (rounds) the network will be trained. For the example dataset, reasonable results can already be observed after 100 epochs. **Default value: 100**\n",
        "\n",
        "* **`patience`:**  Input how many epochs you want to wait without the model improving its results in the validation set to stop training. **Default value: 20**\n",
        "\n",
        "#### **Advanced Parameters - experienced users only**\n",
        "* **`model_architecture`:**  Select the architecture of the DNN used as backbone of the pipeline. Options: EfficientNet B0 and a simple CNN. **Default value: EfficientNet B0**\n",
        "\n",
        "* **`batch_size:`** This parameter defines the number of patches seen in each training step. Reducing or increasing the **batch size** may slow or speed up your training, respectively, and can influence network performance. **Default value: 12**\n",
        "\n",
        "* **`patch_size`:** Input the size of the patches use to train your model (length in pixels in X and Y). The value should be smaller or equal to the dimensions of the image. **Default value: 28**\n",
        "\n",
        "* **`input_channels`:** Input the number of channels of your images (grayscale = 1, RGB = 3). **Default value: 3**\n",
        "\n",
        "* **`optimizer`:** Select the optimizer used to train your model. Options: ADAM, Stocastic Gradient Descent (SGD). ADAM converges usually faster but SGD is known for better generalization. **Default value: SGD**\n",
        "\n",
        "* **`initial_learning_rate`:** Input the initial value to be used as learning rate. If you select ADAM as optimizer, this value should be around 10e-4. **Default value: 0.001**"
      ],
      "metadata": {
        "id": "O75vmD4gugOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Name of the model:\n",
        "model_name = \"my_2d_classification_reduce\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Data management:\n",
        "validation_from_train = True #@param {type:\"boolean\"}\n",
        "percentage_validation =  10 #@param {type:\"number\"}\n",
        "test_ground_truth = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Basic training parameters:\n",
        "number_of_classes = 75#@param {type:\"number\"}\n",
        "number_of_epochs =  100#@param {type:\"number\"}\n",
        "patience =  20#@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Advanced training parameters:\n",
        "\n",
        "model_architecture = \"simple_cnn\" #@param [\"EfficientNetB0\", \"simple_cnn\"]\n",
        "\n",
        "batch_size =  32#@param {type:\"number\"}\n",
        "patch_size = 224 #@param {type:\"number\"}\n",
        "\n",
        "input_channels = 3 #@param {type:\"number\"}\n",
        "\n",
        "optimizer = \"ADAMW\" #@param [\"ADAM\", \"SGD\", \"ADAMW\"]\n",
        "initial_learning_rate = 0.001 #@param {type:\"number\"}"
      ],
      "metadata": {
        "id": "XAFIoaWZubrR"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Play to download the YAML configuration file and update it to train the model\n",
        "import errno\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# remove previous configuration file if it exists with the same name\n",
        "if os.path.exists( yaml_file ):\n",
        "    os.remove( yaml_file )\n",
        "\n",
        "# Download template file\n",
        "import shutil\n",
        "shutil.copy(\"/content/BiaPy/templates/classification/classification_2d.yaml\", yaml_file)\n",
        "\n",
        "# Check folders before modifying the .yaml file\n",
        "if not os.path.exists(train_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_data_path)\n",
        "ids = sorted(next(os.walk(train_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(train_data_path))\n",
        "\n",
        "if not os.path.exists(val_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), val_data_path)\n",
        "ids = sorted(next(os.walk(val_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(val_data_path))\n",
        "\n",
        "if not os.path.exists(test_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_data_path)\n",
        "ids = sorted(next(os.walk(test_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(test_data_path))\n",
        "\n",
        "\n",
        "# open template configuration file\n",
        "import yaml\n",
        "with open( yaml_file, 'r') as stream:\n",
        "    try:\n",
        "        biapy_config = yaml.safe_load(stream)\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)\n",
        "\n",
        "# update paths to data\n",
        "biapy_config['DATA']['TRAIN']['PATH'] = train_data_path\n",
        "biapy_config['DATA']['VAL']['PATH'] = val_data_path\n",
        "biapy_config['DATA']['TEST']['PATH'] = test_data_path\n",
        "biapy_config['DATA']['TEST']['LOAD_GT'] = test_ground_truth\n",
        "\n",
        "# update data patch size\n",
        "biapy_config['DATA']['PATCH_SIZE'] = '('+str(patch_size)+', '+ str(patch_size)+', ' + str(input_channels)+')'\n",
        "# adjust test padding accordingly\n",
        "padding = patch_size // 8\n",
        "biapy_config['DATA']['TEST']['PADDING'] = '('+str(padding)+', '+ str(padding)+')'\n",
        "\n",
        "# update training parameters\n",
        "biapy_config['DATA']['VAL']['FROM_TRAIN'] = validation_from_train\n",
        "biapy_config['DATA']['VAL']['SPLIT_TRAIN'] = percentage_validation/100.0\n",
        "biapy_config['TRAIN']['EPOCHS'] = number_of_epochs\n",
        "biapy_config['TRAIN']['PATIENCE'] = patience\n",
        "biapy_config['TRAIN']['BATCH_SIZE'] = batch_size\n",
        "biapy_config['TRAIN']['OPTIMIZER'] = optimizer\n",
        "biapy_config['TRAIN']['LR'] = initial_learning_rate\n",
        "\n",
        "# Transcribe model architecture\n",
        "# Available models: \"simple_cnn\", \"EfficientNetB0\"\n",
        "architecture = 'simple_cnn'\n",
        "if model_architecture == \"simple_cnn\":\n",
        "    architecture = 'simple_cnn'\n",
        "else:\n",
        "    architecture = 'EfficientNetB0'\n",
        "biapy_config['MODEL']['N_CLASSES'] = number_of_classes\n",
        "biapy_config['MODEL']['ARCHITECTURE'] = architecture\n",
        "\n",
        "# save file\n",
        "with open( yaml_file, 'w') as outfile:\n",
        "    yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Training configuration finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8uemuZM9iI3",
        "outputId": "2eb1a81d-a945-40ce-ade8-78f90f705d93"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training configuration finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def contar_imagenes_en_directorio(directorio):\n",
        "    contador = 0\n",
        "    extensiones_validas = ['.jpg', '.png', '.jpeg', '.gif']  # Puedes agregar m치s extensiones si es necesario\n",
        "\n",
        "    for carpeta, _, archivos in os.walk(directorio):\n",
        "        for archivo in archivos:\n",
        "            _, extension = os.path.splitext(archivo)\n",
        "            if extension.lower() in extensiones_validas:\n",
        "                contador += 1\n",
        "\n",
        "    return contador\n",
        "\n",
        "directorio = \"/content/data/train\"\n",
        "cantidad_imagenes = contar_imagenes_en_directorio(directorio)\n",
        "print(f\"El directorio '{directorio}' contiene {cantidad_imagenes} im치genes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsVAtm19FouF",
        "outputId": "58132b3e-7c37-4d1b-fa73-204307616cda"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El directorio '/content/data/train' contiene 2475 im치genes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def contar_imagenes_en_carpeta(carpeta):\n",
        "    contador = 0\n",
        "    extensiones_validas = ['.jpg', '.png', '.jpeg', '.gif']  # Puedes agregar m치s extensiones si es necesario\n",
        "\n",
        "    for archivo in os.listdir(carpeta):\n",
        "        _, extension = os.path.splitext(archivo)\n",
        "        if extension.lower() in extensiones_validas:\n",
        "            contador += 1\n",
        "\n",
        "    return contador\n",
        "\n",
        "directorio = \"/content/data/train\"\n",
        "\n",
        "for carpeta in os.listdir(directorio):\n",
        "    ruta_carpeta = os.path.join(directorio, carpeta)\n",
        "    if os.path.isdir(ruta_carpeta):\n",
        "        cantidad_imagenes = contar_imagenes_en_carpeta(ruta_carpeta)\n",
        "        print(f\"En la carpeta '{carpeta}' hay {cantidad_imagenes} im치genes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8u-WmNyF4sV",
        "outputId": "0738cea2-77cd-4b9c-9c4d-4b8abda3f4ab"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En la carpeta 'CHECQUERED SKIPPER' hay 95 im치genes.\n",
            "En la carpeta 'PURPLISH COPPER' hay 92 im치genes.\n",
            "En la carpeta 'BANDED PEACOCK' hay 83 im치genes.\n",
            "En la carpeta 'SCARCE SWALLOW' hay 97 im치genes.\n",
            "En la carpeta 'CLEOPATRA' hay 93 im치genes.\n",
            "En la carpeta 'CRECENT' hay 97 im치genes.\n",
            "En la carpeta 'ULYSES' hay 84 im치genes.\n",
            "En la carpeta 'RED SPOTTED PURPLE' hay 86 im치genes.\n",
            "En la carpeta 'PAINTED LADY' hay 78 im치genes.\n",
            "En la carpeta 'CHESTNUT' hay 85 im치genes.\n",
            "En la carpeta 'QUESTION MARK' hay 77 im치genes.\n",
            "En la carpeta 'SOOTYWING' hay 90 im치genes.\n",
            "En la carpeta 'COMMON BANDED AWL' hay 87 im치genes.\n",
            "En la carpeta 'IPHICLUS SISTER' hay 95 im치genes.\n",
            "En la carpeta 'ORCHARD SWALLOW' hay 76 im치genes.\n",
            "En la carpeta 'RED ADMIRAL' hay 82 im치genes.\n",
            "En la carpeta 'AN 88' hay 85 im치genes.\n",
            "En la carpeta 'PURPLE HAIRSTREAK' hay 79 im치genes.\n",
            "En la carpeta 'ORANGE OAKLEAF' hay 87 im치genes.\n",
            "En la carpeta 'LARGE MARBLE' hay 81 im치genes.\n",
            "En la carpeta 'RED CRACKER' hay 96 im치genes.\n",
            "En la carpeta 'MALACHITE' hay 73 im치genes.\n",
            "En la carpeta 'DANAID EGGFLY' hay 94 im치genes.\n",
            "En la carpeta 'SOUTHERN DOGFACE' hay 87 im치genes.\n",
            "En la carpeta 'EASTERN PINE ELFIN' hay 95 im치genes.\n",
            "En la carpeta 'BROWN SIPROETA' hay 99 im치genes.\n",
            "En la carpeta 'CABBAGE WHITE' hay 90 im치genes.\n",
            "En la carpeta 'APPOLLO' hay 90 im치genes.\n",
            "En la carpeta 'COMMON WOOD-NYMPH' hay 90 im치genes.\n",
            "En la carpeta 'MESTRA' hay 86 im치genes.\n",
            "En la carpeta 'EASTERN DAPPLE WHITE' hay 92 im치genes.\n",
            "En la carpeta 'GREAT EGGFLY' hay 78 im치genes.\n",
            "En la carpeta 'BLACK HAIRSTREAK' hay 85 im치genes.\n",
            "En la carpeta 'MANGROVE SKIPPER' hay 87 im치genes.\n",
            "En la carpeta 'MONARCH' hay 90 im치genes.\n",
            "En la carpeta 'ORANGE TIP' hay 96 im치genes.\n",
            "En la carpeta 'GOLD BANDED' hay 73 im치genes.\n",
            "En la carpeta 'MILBERTS TORTOISESHELL' hay 96 im치genes.\n",
            "En la carpeta 'CLOUDED SULPHUR' hay 92 im치genes.\n",
            "En la carpeta 'BANDED ORANGE HELICONIAN' hay 97 im치genes.\n",
            "En la carpeta 'GREEN CELLED CATTLEHEART' hay 88 im치genes.\n",
            "En la carpeta 'JULIA' hay 81 im치genes.\n",
            "En la carpeta 'SILVER SPOT SKIPPER' hay 83 im치genes.\n",
            "En la carpeta 'TWO BARRED FLASHER' hay 76 im치genes.\n",
            "En la carpeta 'PINE WHITE' hay 86 im치genes.\n",
            "En la carpeta 'COPPER TAIL' hay 94 im치genes.\n",
            "En la carpeta 'PEACOCK' hay 84 im치genes.\n",
            "En la carpeta 'SLEEPY ORANGE' hay 107 im치genes.\n",
            "En la carpeta 'PAPER KITE' hay 90 im치genes.\n",
            "En la carpeta 'WOOD SATYR' hay 71 im치genes.\n",
            "En la carpeta 'TROPICAL LEAFWING' hay 83 im치genes.\n",
            "En la carpeta 'VICEROY' hay 81 im치genes.\n",
            "En la carpeta 'AMERICAN SNOOT' hay 74 im치genes.\n",
            "En la carpeta 'BLUE SPOTTED CROW' hay 86 im치genes.\n",
            "En la carpeta 'AFRICAN GIANT SWALLOWTAIL' hay 75 im치genes.\n",
            "En la carpeta 'GREY HAIRSTREAK' hay 86 im치genes.\n",
            "En la carpeta 'CAIRNS BIRDWING' hay 83 im치genes.\n",
            "En la carpeta 'INDRA SWALLOW' hay 81 im치genes.\n",
            "En la carpeta 'GREAT JAY' hay 94 im치genes.\n",
            "En la carpeta 'ATALA' hay 100 im치genes.\n",
            "En la carpeta 'BECKERS WHITE' hay 81 im치genes.\n",
            "En la carpeta 'PIPEVINE SWALLOW' hay 84 im치genes.\n",
            "En la carpeta 'ZEBRA LONG WING' hay 76 im치genes.\n",
            "En la carpeta 'RED POSTMAN' hay 89 im치genes.\n",
            "En la carpeta 'ADONIS' hay 88 im치genes.\n",
            "En la carpeta 'BLUE MORPHO' hay 75 im치genes.\n",
            "En la carpeta 'ELBOWED PIERROT' hay 82 im치genes.\n",
            "En la carpeta 'YELLOW SWALLOW TAIL' hay 75 im치genes.\n",
            "En la carpeta 'POPINJAY' hay 85 im치genes.\n",
            "En la carpeta 'CLODIUS PARNASSIAN' hay 87 im치genes.\n",
            "En la carpeta 'STRAITED QUEEN' hay 87 im치genes.\n",
            "En la carpeta 'EASTERN COMA' hay 93 im치genes.\n",
            "En la carpeta 'CRIMSON PATCH' hay 72 im치genes.\n",
            "En la carpeta 'METALMARK' hay 76 im치genes.\n",
            "En la carpeta 'MOURNING CLOAK' hay 131 im치genes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def contar_imagenes_en_carpeta(carpeta):\n",
        "    contador = 0\n",
        "    extensiones_validas = ['.jpg', '.png', '.jpeg', '.gif']  # Puedes agregar m치s extensiones si es necesario\n",
        "\n",
        "    for archivo in os.listdir(carpeta):\n",
        "        _, extension = os.path.splitext(archivo)\n",
        "        if extension.lower() in extensiones_validas:\n",
        "            contador += 1\n",
        "\n",
        "    return contador\n",
        "\n",
        "def eliminar_imagenes_excedentes(carpeta, objetivo):\n",
        "    imagenes_actuales = contar_imagenes_en_carpeta(carpeta)\n",
        "    excedentes = imagenes_actuales - objetivo\n",
        "\n",
        "    if excedentes <= 0:\n",
        "        return\n",
        "\n",
        "    imagenes_a_eliminar = random.sample(os.listdir(carpeta), excedentes)\n",
        "    for imagen in imagenes_a_eliminar:\n",
        "        ruta_imagen = os.path.join(carpeta, imagen)\n",
        "        os.remove(ruta_imagen)\n",
        "\n",
        "directorio = \"/content/data/train\"\n",
        "objetivo_total_imagenes = 2500\n",
        "objetivo_por_carpeta = objetivo_total_imagenes // len(os.listdir(directorio))\n",
        "\n",
        "for carpeta in os.listdir(directorio):\n",
        "    ruta_carpeta = os.path.join(directorio, carpeta)\n",
        "    if os.path.isdir(ruta_carpeta):\n",
        "        eliminar_imagenes_excedentes(ruta_carpeta, objetivo_por_carpeta)\n",
        "\n",
        "cantidad_total_imagenes = sum(contar_imagenes_en_carpeta(os.path.join(directorio, carpeta)) for carpeta in os.listdir(directorio))\n",
        "print(f\"Se ha logrado un total de aproximadamente {cantidad_total_imagenes} im치genes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgrLCajuGabV",
        "outputId": "04a608f3-2f9c-4013-bbc8-01b8cd2a3801"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se ha logrado un total de aproximadamente 2475 im치genes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for carpeta in os.listdir(directorio):\n",
        "    ruta_carpeta = os.path.join(directorio, carpeta)\n",
        "    if os.path.isdir(ruta_carpeta):\n",
        "        cantidad_imagenes = contar_imagenes_en_carpeta(ruta_carpeta)\n",
        "        print(f\"En la carpeta '{carpeta}' hay {cantidad_imagenes} im치genes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6LicTavGgUd",
        "outputId": "caa0397d-5806-4b14-95c3-08ab912f2d8a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En la carpeta 'CHECQUERED SKIPPER' hay 33 im치genes.\n",
            "En la carpeta 'PURPLISH COPPER' hay 33 im치genes.\n",
            "En la carpeta 'BANDED PEACOCK' hay 33 im치genes.\n",
            "En la carpeta 'SCARCE SWALLOW' hay 33 im치genes.\n",
            "En la carpeta 'CLEOPATRA' hay 33 im치genes.\n",
            "En la carpeta 'CRECENT' hay 33 im치genes.\n",
            "En la carpeta 'ULYSES' hay 33 im치genes.\n",
            "En la carpeta 'RED SPOTTED PURPLE' hay 33 im치genes.\n",
            "En la carpeta 'PAINTED LADY' hay 33 im치genes.\n",
            "En la carpeta 'CHESTNUT' hay 33 im치genes.\n",
            "En la carpeta 'QUESTION MARK' hay 33 im치genes.\n",
            "En la carpeta 'SOOTYWING' hay 33 im치genes.\n",
            "En la carpeta 'COMMON BANDED AWL' hay 33 im치genes.\n",
            "En la carpeta 'IPHICLUS SISTER' hay 33 im치genes.\n",
            "En la carpeta 'ORCHARD SWALLOW' hay 33 im치genes.\n",
            "En la carpeta 'RED ADMIRAL' hay 33 im치genes.\n",
            "En la carpeta 'AN 88' hay 33 im치genes.\n",
            "En la carpeta 'PURPLE HAIRSTREAK' hay 33 im치genes.\n",
            "En la carpeta 'ORANGE OAKLEAF' hay 33 im치genes.\n",
            "En la carpeta 'LARGE MARBLE' hay 33 im치genes.\n",
            "En la carpeta 'RED CRACKER' hay 33 im치genes.\n",
            "En la carpeta 'MALACHITE' hay 33 im치genes.\n",
            "En la carpeta 'DANAID EGGFLY' hay 33 im치genes.\n",
            "En la carpeta 'SOUTHERN DOGFACE' hay 33 im치genes.\n",
            "En la carpeta 'EASTERN PINE ELFIN' hay 33 im치genes.\n",
            "En la carpeta 'BROWN SIPROETA' hay 33 im치genes.\n",
            "En la carpeta 'CABBAGE WHITE' hay 33 im치genes.\n",
            "En la carpeta 'APPOLLO' hay 33 im치genes.\n",
            "En la carpeta 'COMMON WOOD-NYMPH' hay 33 im치genes.\n",
            "En la carpeta 'MESTRA' hay 33 im치genes.\n",
            "En la carpeta 'EASTERN DAPPLE WHITE' hay 33 im치genes.\n",
            "En la carpeta 'GREAT EGGFLY' hay 33 im치genes.\n",
            "En la carpeta 'BLACK HAIRSTREAK' hay 33 im치genes.\n",
            "En la carpeta 'MANGROVE SKIPPER' hay 33 im치genes.\n",
            "En la carpeta 'MONARCH' hay 33 im치genes.\n",
            "En la carpeta 'ORANGE TIP' hay 33 im치genes.\n",
            "En la carpeta 'GOLD BANDED' hay 33 im치genes.\n",
            "En la carpeta 'MILBERTS TORTOISESHELL' hay 33 im치genes.\n",
            "En la carpeta 'CLOUDED SULPHUR' hay 33 im치genes.\n",
            "En la carpeta 'BANDED ORANGE HELICONIAN' hay 33 im치genes.\n",
            "En la carpeta 'GREEN CELLED CATTLEHEART' hay 33 im치genes.\n",
            "En la carpeta 'JULIA' hay 33 im치genes.\n",
            "En la carpeta 'SILVER SPOT SKIPPER' hay 33 im치genes.\n",
            "En la carpeta 'TWO BARRED FLASHER' hay 33 im치genes.\n",
            "En la carpeta 'PINE WHITE' hay 33 im치genes.\n",
            "En la carpeta 'COPPER TAIL' hay 33 im치genes.\n",
            "En la carpeta 'PEACOCK' hay 33 im치genes.\n",
            "En la carpeta 'SLEEPY ORANGE' hay 33 im치genes.\n",
            "En la carpeta 'PAPER KITE' hay 33 im치genes.\n",
            "En la carpeta 'WOOD SATYR' hay 33 im치genes.\n",
            "En la carpeta 'TROPICAL LEAFWING' hay 33 im치genes.\n",
            "En la carpeta 'VICEROY' hay 33 im치genes.\n",
            "En la carpeta 'AMERICAN SNOOT' hay 33 im치genes.\n",
            "En la carpeta 'BLUE SPOTTED CROW' hay 33 im치genes.\n",
            "En la carpeta 'AFRICAN GIANT SWALLOWTAIL' hay 33 im치genes.\n",
            "En la carpeta 'GREY HAIRSTREAK' hay 33 im치genes.\n",
            "En la carpeta 'CAIRNS BIRDWING' hay 33 im치genes.\n",
            "En la carpeta 'INDRA SWALLOW' hay 33 im치genes.\n",
            "En la carpeta 'GREAT JAY' hay 33 im치genes.\n",
            "En la carpeta 'ATALA' hay 33 im치genes.\n",
            "En la carpeta 'BECKERS WHITE' hay 33 im치genes.\n",
            "En la carpeta 'PIPEVINE SWALLOW' hay 33 im치genes.\n",
            "En la carpeta 'ZEBRA LONG WING' hay 33 im치genes.\n",
            "En la carpeta 'RED POSTMAN' hay 33 im치genes.\n",
            "En la carpeta 'ADONIS' hay 33 im치genes.\n",
            "En la carpeta 'BLUE MORPHO' hay 33 im치genes.\n",
            "En la carpeta 'ELBOWED PIERROT' hay 33 im치genes.\n",
            "En la carpeta 'YELLOW SWALLOW TAIL' hay 33 im치genes.\n",
            "En la carpeta 'POPINJAY' hay 33 im치genes.\n",
            "En la carpeta 'CLODIUS PARNASSIAN' hay 33 im치genes.\n",
            "En la carpeta 'STRAITED QUEEN' hay 33 im치genes.\n",
            "En la carpeta 'EASTERN COMA' hay 33 im치genes.\n",
            "En la carpeta 'CRIMSON PATCH' hay 33 im치genes.\n",
            "En la carpeta 'METALMARK' hay 33 im치genes.\n",
            "En la carpeta 'MOURNING CLOAK' hay 33 im치genes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Play to train the model\n",
        "\n",
        "import os\n",
        "import errno\n",
        "\n",
        "# Run the code\n",
        "os.chdir('/content/BiaPy')\n",
        "!python -u main.py --config '/content/'{job_name}'.yaml' --result_dir {output_path} --name {job_name} --run_id 1 --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao0NDdReCaxW",
        "outputId": "4f236a03-8541-4e82-c277-55d3a322e81e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date: 2023-07-27 11:29:10\n",
            "Arguments: Namespace(config='/content/my_2d_classification_reduce.yaml', result_dir='/content/output', name='my_2d_classification_reduce', run_id=1, gpu='0')\n",
            "Job: my_2d_classification_reduce_1\n",
            "Python       : 3.10.6 (main, May 29 2023, 11:10:38) [GCC 11.3.0]\n",
            "Keras        : 2.12.0\n",
            "Tensorflow   : 2.12.0\n",
            "Num GPUs Available:  0\n",
            "Configuration details:\n",
            "AUGMENTOR:\n",
            "  AFFINE_MODE: constant\n",
            "  AUG_NUM_SAMPLES: 10\n",
            "  AUG_SAMPLES: True\n",
            "  BRIGHTNESS: False\n",
            "  BRIGHTNESS_EM: False\n",
            "  BRIGHTNESS_EM_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_EM_MODE: 3D\n",
            "  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_MODE: 3D\n",
            "  CBLUR_DOWN_RANGE: (2, 8)\n",
            "  CBLUR_INSIDE: True\n",
            "  CBLUR_SIZE: (0.2, 0.4)\n",
            "  CHANNEL_SHUFFLE: False\n",
            "  CMIX_SIZE: (0.2, 0.4)\n",
            "  CNOISE_NB_ITERATIONS: (1, 3)\n",
            "  CNOISE_SCALE: (0.05, 0.1)\n",
            "  CNOISE_SIZE: (0.2, 0.4)\n",
            "  CONTRAST: False\n",
            "  CONTRAST_EM: False\n",
            "  CONTRAST_EM_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_EM_MODE: 3D\n",
            "  CONTRAST_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_MODE: 3D\n",
            "  COUT_APPLY_TO_MASK: False\n",
            "  COUT_CVAL: 0.0\n",
            "  COUT_NB_ITERATIONS: (1, 3)\n",
            "  COUT_SIZE: (0.05, 0.3)\n",
            "  CUTBLUR: False\n",
            "  CUTMIX: False\n",
            "  CUTNOISE: False\n",
            "  CUTOUT: False\n",
            "  DA_PROB: 0.5\n",
            "  DRAW_GRID: True\n",
            "  DROPOUT: False\n",
            "  DROP_RANGE: (0, 0.2)\n",
            "  ELASTIC: False\n",
            "  ENABLE: True\n",
            "  E_ALPHA: (12, 16)\n",
            "  E_MODE: constant\n",
            "  E_SIGMA: 4\n",
            "  GAMMA_CONTRAST: False\n",
            "  GAUSSIAN_NOISE: False\n",
            "  GAUSSIAN_NOISE_MEAN: 0.0\n",
            "  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n",
            "  GAUSSIAN_NOISE_VAR: 0.05\n",
            "  GC_GAMMA: (1.25, 1.75)\n",
            "  GRAYSCALE: False\n",
            "  GRIDMASK: False\n",
            "  GRID_D_RANGE: (0.4, 1)\n",
            "  GRID_INVERT: False\n",
            "  GRID_RATIO: 0.6\n",
            "  GRID_ROTATE: 1.0\n",
            "  G_BLUR: False\n",
            "  G_SIGMA: (1.0, 2.0)\n",
            "  HFLIP: True\n",
            "  MB_KERNEL: (3, 7)\n",
            "  MEDIAN_BLUR: False\n",
            "  MISALIGNMENT: False\n",
            "  MISSING_SECTIONS: False\n",
            "  MISSP_ITERATIONS: (10, 30)\n",
            "  MOTB_K_RANGE: (8, 12)\n",
            "  MOTION_BLUR: False\n",
            "  MS_DISPLACEMENT: 16\n",
            "  MS_ROTATE_RATIO: 0.5\n",
            "  PEPPER: False\n",
            "  PEPPER_AMOUNT: 0.05\n",
            "  POISSON_NOISE: False\n",
            "  RANDOM_ROT: True\n",
            "  RANDOM_ROT_RANGE: (-180, 180)\n",
            "  ROT90: False\n",
            "  SALT: False\n",
            "  SALT_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER: False\n",
            "  SALT_AND_PEPPER_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER_PROP: 0.5\n",
            "  SHEAR: False\n",
            "  SHEAR_RANGE: (-20, 20)\n",
            "  SHIFT: False\n",
            "  SHIFT_RANGE: (0.1, 0.2)\n",
            "  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n",
            "  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n",
            "  VFLIP: True\n",
            "  ZFLIP: False\n",
            "  ZOOM: False\n",
            "  ZOOM_RANGE: (0.8, 1.2)\n",
            "DATA:\n",
            "  CHECK_GENERATORS: False\n",
            "  EXTRACT_RANDOM_PATCH: False\n",
            "  NORMALIZATION:\n",
            "    CUSTOM_MEAN: -1.0\n",
            "    CUSTOM_STD: -1.0\n",
            "    TYPE: div\n",
            "  PATCH_SIZE: (224, 224, 3)\n",
            "  PROBABILITY_MAP: False\n",
            "  REFLECT_TO_COMPLETE_SHAPE: False\n",
            "  TEST:\n",
            "    ARGMAX_TO_OUTPUT: False\n",
            "    BINARY_MASKS: /content/data/t_test/../bin_mask\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/test/y_detection_masks\n",
            "    GT_PATH: user_data/test/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/t_test_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/test/y_BC_thick\n",
            "    IN_MEMORY: False\n",
            "    LOAD_GT: False\n",
            "    MEDIAN_PADDING: False\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (28, 28)\n",
            "    PATH: /content/data/t_test\n",
            "    RESOLUTION: (1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/t_test_ssl_source\n",
            "    USE_VAL_AS_TEST: False\n",
            "  TRAIN:\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/train/y_detection_masks\n",
            "    GT_PATH: user_data/train/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/train/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    MINIMUM_FOREGROUND_PER: -1.0\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (0, 0)\n",
            "    PATH: /content/data/train\n",
            "    REPLICATE: 0\n",
            "    RESOLUTION: (1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train_ssl_source\n",
            "  VAL:\n",
            "    BINARY_MASKS: /content/data/train/../bin_mask\n",
            "    CROSS_VAL: False\n",
            "    CROSS_VAL_FOLD: 1\n",
            "    CROSS_VAL_NFOLD: 5\n",
            "    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n",
            "    FROM_TRAIN: True\n",
            "    GT_PATH: user_data/val/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (0, 0)\n",
            "    PATH: /content/data/train\n",
            "    RANDOM: True\n",
            "    RESOLUTION: (1, 1)\n",
            "    SPLIT_TRAIN: 0.1\n",
            "    SSL_SOURCE_DIR: /content/data/train_ssl_source\n",
            "  W_BACKGROUND: 0.06\n",
            "  W_FOREGROUND: 0.94\n",
            "LOSS:\n",
            "  TYPE: CE\n",
            "MODEL:\n",
            "  ACTIVATION: elu\n",
            "  ARCHITECTURE: simple_cnn\n",
            "  BATCH_NORMALIZATION: False\n",
            "  DROPOUT_VALUES: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "  FEATURE_MAPS: [16, 32, 64, 128, 256]\n",
            "  KERNEL_INIT: he_normal\n",
            "  KERNEL_SIZE: 3\n",
            "  LAST_ACTIVATION: sigmoid\n",
            "  LOAD_CHECKPOINT: False\n",
            "  MAKE_PLOT: False\n",
            "  N_CLASSES: 75\n",
            "  SPATIAL_DROPOUT: False\n",
            "  TIRAMISU_DEPTH: 3\n",
            "  UNETR_DEC_ACTIVATION: relu\n",
            "  UNETR_DEC_KERNEL_INIT: he_normal\n",
            "  UNETR_VIT_HIDD_MULT: 3\n",
            "  UNETR_VIT_NUM_FILTERS: 16\n",
            "  UPSAMPLE_LAYER: convtranspose\n",
            "  VIT_HIDDEN_SIZE: 768\n",
            "  VIT_MLP_DIMS: 3072\n",
            "  VIT_NUM_HEADS: 12\n",
            "  VIT_NUM_LAYERS: 12\n",
            "  VIT_TOKEN_SIZE: 16\n",
            "  Z_DOWN: [0, 0, 0, 0]\n",
            "PATHS:\n",
            "  CHARTS: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/charts\n",
            "  CHECKPOINT: /content/output/my_2d_classification_reduce/checkpoints\n",
            "  CHECKPOINT_FILE: /content/output/my_2d_classification_reduce/checkpoints/model_weights_my_2d_classification_reduce_1.h5\n",
            "  DA_SAMPLES: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/aug\n",
            "  GEN_CHECKS: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/gen_check\n",
            "  GEN_MASK_CHECKS: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/gen_mask_check\n",
            "  MEAN_INFO_FILE: /content/output/my_2d_classification_reduce/checkpoints/normalization_mean_value.npy\n",
            "  PROB_MAP_DIR: /content/output/my_2d_classification_reduce/prob_map\n",
            "  PROB_MAP_FILENAME: prob_map.npy\n",
            "  PROFILER: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/profiler\n",
            "  RESULT_DIR:\n",
            "    AS_3D_STACK_POST_PROCESSING: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/as_3d_stack_post_processing\n",
            "    DET_ASSOC_POINTS: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/point_associations\n",
            "    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/per_image_local_max_check\n",
            "    FULL_IMAGE: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/full_image\n",
            "    FULL_IMAGE_BIN: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/full_image_binarized\n",
            "    INST_ASSOC_POINTS: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/instance_associations\n",
            "    PATH: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1\n",
            "    PER_IMAGE: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/per_image\n",
            "    PER_IMAGE_BIN: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/per_image_binarized\n",
            "    PER_IMAGE_INSTANCES: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/per_image_instances\n",
            "    PER_IMAGE_POST_PROCESSING: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/per_image_post_processing\n",
            "  STD_INFO_FILE: /content/output/my_2d_classification_reduce/checkpoints/normalization_std_value.npy\n",
            "  TEST_FULL_GT_H5: user_data/test/y/h5\n",
            "  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/test_BC_instance_channels\n",
            "  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/train_BC_instance_channels\n",
            "  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/val_BC_instance_channels\n",
            "  WATERSHED_DIR: /content/output/my_2d_classification_reduce/results/my_2d_classification_reduce_1/watershed\n",
            "PROBLEM:\n",
            "  DENOISING:\n",
            "    N2V_MANIPULATOR: uniform_withCP\n",
            "    N2V_NEIGHBORHOOD_RADIUS: 5\n",
            "    N2V_PERC_PIX: 0.198\n",
            "    N2V_STRUCTMASK: False\n",
            "  DETECTION:\n",
            "    CENTRAL_POINT_DILATION: 3\n",
            "    CHECK_POINTS_CREATED: True\n",
            "    DATA_CHECK_MW: True\n",
            "  INSTANCE_SEG:\n",
            "    DATA_CHANNELS: BC\n",
            "    DATA_CHANNEL_WEIGHTS: (1, 1)\n",
            "    DATA_CHECK_MW: True\n",
            "    DATA_CONTOUR_MODE: thick\n",
            "    DATA_MW_OPTIMIZE_THS: False\n",
            "    DATA_MW_TH_BINARY_MASK: 0.5\n",
            "    DATA_MW_TH_CONTOUR: 0.1\n",
            "    DATA_MW_TH_DISTANCE: 2.0\n",
            "    DATA_MW_TH_DIST_FOREGROUND: 1.2\n",
            "    DATA_MW_TH_FOREGROUND: 0.3\n",
            "    DATA_MW_TH_POINTS: 0.5\n",
            "    DATA_REMOVE_AFTER_MW: False\n",
            "    DATA_REMOVE_BEFORE_MW: False\n",
            "    DATA_REMOVE_SMALL_OBJ_AFTER: 100\n",
            "    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n",
            "    ERODE_AND_DILATE_FOREGROUND: False\n",
            "    FORE_DILATION_RADIUS: 5\n",
            "    FORE_EROSION_RADIUS: 5\n",
            "    SEED_MORPH_RADIUS: []\n",
            "    SEED_MORPH_SEQUENCE: []\n",
            "  NDIM: 2D\n",
            "  SELF_SUPERVISED:\n",
            "    NOISE: 0.2\n",
            "    PRETEXT_TASK: crappify\n",
            "    RESIZING_FACTOR: 4\n",
            "  SUPER_RESOLUTION:\n",
            "    UPSCALING: 1\n",
            "  TYPE: CLASSIFICATION\n",
            "SYSTEM:\n",
            "  NUM_CPUS: -1\n",
            "  SEED: 0\n",
            "TEST:\n",
            "  ANALIZE_2D_IMGS_AS_3D_STACK: False\n",
            "  AUGMENTATION: False\n",
            "  DET_LOCAL_MAX_COORDS: False\n",
            "  DET_MIN_TH_TO_BE_PEAK: [0.2]\n",
            "  DET_TOLERANCE: [10]\n",
            "  ENABLE: True\n",
            "  EVALUATE: True\n",
            "  MATCHING_SEGCOMPARE: False\n",
            "  MATCHING_STATS: True\n",
            "  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n",
            "  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n",
            "  POST_PROCESSING:\n",
            "    APPLY_MASK: False\n",
            "    DET_WATERSHED: False\n",
            "    DET_WATERSHED_DONUTS_CLASSES: [-1]\n",
            "    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n",
            "    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n",
            "    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n",
            "    REMOVE_CLOSE_POINTS: False\n",
            "    REMOVE_CLOSE_POINTS_RADIUS: [-1.0]\n",
            "    REPARE_LARGE_BLOBS_SIZE: -1\n",
            "    VORONOI_ON_MASK: False\n",
            "    VORONOI_TH: 0.0\n",
            "    WATERSHED_CIRCULARITY: -1.0\n",
            "    YZ_FILTERING: False\n",
            "    YZ_FILTERING_SIZE: 5\n",
            "    Z_FILTERING: False\n",
            "    Z_FILTERING_SIZE: 5\n",
            "  REDUCE_MEMORY: False\n",
            "  STATS:\n",
            "    FULL_IMG: True\n",
            "    MERGE_PATCHES: False\n",
            "    PER_PATCH: False\n",
            "  VERBOSE: True\n",
            "TRAIN:\n",
            "  BATCH_SIZE: 32\n",
            "  CHECKPOINT_MONITOR: val_loss\n",
            "  EARLYSTOPPING_MONITOR: val_loss\n",
            "  ENABLE: True\n",
            "  EPOCHS: 100\n",
            "  LR: 0.001\n",
            "  LR_SCHEDULER:\n",
            "    MIN_LR: -1.0\n",
            "    NAME: \n",
            "    REDUCEONPLATEAU_FACTOR: 0.5\n",
            "    REDUCEONPLATEAU_PATIENCE: -1\n",
            "    WARMUP_COSINE_DECAY_EPOCHS: -1\n",
            "    WARMUP_COSINE_DECAY_HOLD_EPOCHS: -1\n",
            "    WARMUP_COSINE_DECAY_LR: -1.0\n",
            "  OPTIMIZER: ADAMW\n",
            "  PATIENCE: 20\n",
            "  PROFILER: False\n",
            "  PROFILER_BATCH_RANGE: 10, 100\n",
            "  W_DECAY: 0.004\n",
            "####################\n",
            "#  PRE-PROCESSING  #\n",
            "####################\n",
            "\n",
            "#################\n",
            "#   LOAD DATA   #\n",
            "#################\n",
            "\n",
            "### LOAD ###\n",
            "*** Loaded train data shape is: (5849, 224, 224, 3)\n",
            "*** Loaded validation data shape is: (650, 224, 224, 3)\n",
            "### END LOAD ###\n",
            "### LOAD ###\n",
            "*** Loaded test data shape is: (2786, 224, 224, 3)\n",
            "########################\n",
            "#  PREPARE GENERATORS  #\n",
            "########################\n",
            "\n",
            "Initializing train data generator . . .\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}